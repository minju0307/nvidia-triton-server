{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f1e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nemo_toolkit[nlp]\n",
      "  Cloning https://github.com/NVIDIA/NeMo.git (to revision r1.12.0) to /tmp/pip-install-djeo3les/nemo-toolkit\n",
      "  Running command git clone -q https://github.com/NVIDIA/NeMo.git /tmp/pip-install-djeo3les/nemo-toolkit\n",
      "  Running command git checkout -b r1.12.0 --track origin/r1.12.0\n",
      "  Switched to a new branch 'r1.12.0'\n",
      "  Branch 'r1.12.0' set up to track remote branch 'r1.12.0' from 'origin'.\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting frozendict\n",
      "  Downloading frozendict-2.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface_hub in ./myenv3/lib/python3.8/site-packages (from nemo_toolkit[nlp]) (0.10.1)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting numba\n",
      "  Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21 in ./myenv3/lib/python3.8/site-packages (from nemo_toolkit[nlp]) (1.23.4)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting onnx>=1.7.0\n",
      "  Downloading onnx-1.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in ./myenv3/lib/python3.8/site-packages (from nemo_toolkit[nlp]) (2.8.2)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting ruamel.yaml\n",
      "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 8.6 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 8.5 MB/s eta 0:00:012\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001b[K     |████████████████████████████████| 952 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch in ./myenv3/lib/python3.8/site-packages (from nemo_toolkit[nlp]) (1.12.1+cu116)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in ./myenv3/lib/python3.8/site-packages (from nemo_toolkit[nlp]) (4.64.1)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 8.0 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 10.0 MB/s ta 0:00:011\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.26.8-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 7.6 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 9.3 MB/s  eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.6 MB 9.2 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 9.2 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting flask_restful\n",
      "  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 10.3 MB/s ta 0:00:011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting gdown\n",
      "  Downloading gdown-4.5.3.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 8.5 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting hydra-core<1.2,>=1.1.0\n",
      "  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 8.0 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting ijson\n",
      "  Downloading ijson-3.1.4-cp38-cp38-manylinux2010_x86_64.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 7.8 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting inflect\n",
      "  Downloading inflect-6.0.2-py3-none-any.whl (34 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 7.4 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting matplotlib>=3.3.2\n",
      "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.4 MB 7.3 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting nltk>=3.6.5\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 8.3 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting omegaconf<2.2,>=2.1.2\n",
      "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 9.4 MB/s eta 0:00:011\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting opencc\n",
      "  Downloading OpenCC-1.1.4-cp38-cp38-manylinux1_x86_64.whl (770 kB)\n",
      "\u001b[K     |████████████████████████████████| 770 kB 7.9 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 7.5 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting pangu\n",
      "  Downloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting pytorch-lightning<=1.7.6,>=1.7.0\n",
      "  Downloading pytorch_lightning-1.7.6-py3-none-any.whl (707 kB)\n",
      "\u001b[K     |████████████████████████████████| 707 kB 8.5 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting pyyaml<6\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "\u001b[K     |████████████████████████████████| 662 kB 8.3 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting rapidfuzz\n",
      "  Downloading rapidfuzz-2.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in ./myenv3/lib/python3.8/site-packages (from nemo_toolkit[nlp]) (2022.10.31)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting sacrebleu[ja]\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 8.4 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting sacremoses>=0.0.43\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 880 kB 8.2 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 8.7 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting sentencepiece<1.0.0\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchmetrics>=0.4.1rc0 in ./myenv3/lib/python3.8/site-packages (from nemo_toolkit[nlp]) (0.10.2)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting transformers<=4.21.2,>=4.0.1\n",
      "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 8.5 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 8.3 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting webdataset<=0.1.62,>=0.1.48\n",
      "  Downloading webdataset-0.1.62-py3-none-any.whl (32 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting youtokentome>=1.0.5\n",
      "  Downloading youtokentome-1.0.6-cp38-cp38-manylinux2010_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in ./myenv3/lib/python3.8/site-packages (from huggingface_hub->nemo_toolkit[nlp]) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./myenv3/lib/python3.8/site-packages (from huggingface_hub->nemo_toolkit[nlp]) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv3/lib/python3.8/site-packages (from huggingface_hub->nemo_toolkit[nlp]) (4.4.0)\n",
      "Requirement already satisfied: filelock in ./myenv3/lib/python3.8/site-packages (from huggingface_hub->nemo_toolkit[nlp]) (3.8.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in ./myenv3/lib/python3.8/site-packages (from numba->nemo_toolkit[nlp]) (5.0.0)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.6 MB 7.2 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting protobuf<=3.20.1,>=3.12.2\n",
      "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./myenv3/lib/python3.8/site-packages (from python-dateutil->nemo_toolkit[nlp]) (1.16.0)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting ruamel.yaml.clib>=0.2.6; platform_python_implementation == \"CPython\" and python_version < \"3.11\"\n",
      "  Downloading ruamel.yaml.clib-0.2.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (555 kB)\n",
      "\u001b[K     |████████████████████████████████| 555 kB 8.5 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting joblib>=1.0.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 8.1 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.8 MB 7.3 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.6 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting botocore<1.30.0,>=1.29.8\n",
      "  Downloading botocore-1.29.8-py3-none-any.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in ./myenv3/lib/python3.8/site-packages (from fasttext->nemo_toolkit[nlp]) (2.10.1)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting Flask>=0.8\n",
      "  Downloading Flask-2.2.2-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 9.2 MB/s ta 0:00:011\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting aniso8601>=0.82\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 10.5 MB/s ta 0:00:011\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting pytz\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001b[K     |████████████████████████████████| 498 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in ./myenv3/lib/python3.8/site-packages (from ftfy->nemo_toolkit[nlp]) (0.2.5)\n",
      "Requirement already satisfied: beautifulsoup4 in ./myenv3/lib/python3.8/site-packages (from gdown->nemo_toolkit[nlp]) (4.11.1)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting importlib-resources<5.3; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 8.2 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting pydantic>=1.9.1\n",
      "  Downloading pydantic-1.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6 MB 7.4 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
      "\u001b[K     |████████████████████████████████| 295 kB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in ./myenv3/lib/python3.8/site-packages (from matplotlib>=3.3.2->nemo_toolkit[nlp]) (3.0.9)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 7.9 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in ./myenv3/lib/python3.8/site-packages (from matplotlib>=3.3.2->nemo_toolkit[nlp]) (9.3.0)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 9.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: tensorboard>=2.9.1 in ./myenv3/lib/python3.8/site-packages (from pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (2.11.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in ./myenv3/lib/python3.8/site-packages (from pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (2022.11.0)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 7.9 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting mecab-python3==1.0.5; extra == \"ja\"\n",
      "  Downloading mecab_python3-1.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (577 kB)\n",
      "\u001b[K     |████████████████████████████████| 577 kB 8.6 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting ipadic<2.0,>=1.0; extra == \"ja\"\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in ./myenv3/lib/python3.8/site-packages (from sentence_transformers->nemo_toolkit[nlp]) (0.13.1+cu116)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 8.3 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 8.6 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 7.9 MB/s eta 0:00:01\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\u001b[?25hCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./myenv3/lib/python3.8/site-packages (from wandb->nemo_toolkit[nlp]) (5.9.4)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting braceexpand\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./myenv3/lib/python3.8/site-packages (from requests->huggingface_hub->nemo_toolkit[nlp]) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv3/lib/python3.8/site-packages (from requests->huggingface_hub->nemo_toolkit[nlp]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv3/lib/python3.8/site-packages (from requests->huggingface_hub->nemo_toolkit[nlp]) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./myenv3/lib/python3.8/site-packages (from requests->huggingface_hub->nemo_toolkit[nlp]) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./myenv3/lib/python3.8/site-packages (from importlib-metadata; python_version < \"3.9\"->numba->nemo_toolkit[nlp]) (3.10.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in ./myenv3/lib/python3.8/site-packages (from Flask>=0.8->flask_restful->nemo_toolkit[nlp]) (3.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in ./myenv3/lib/python3.8/site-packages (from Flask>=0.8->flask_restful->nemo_toolkit[nlp]) (2.2.2)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./myenv3/lib/python3.8/site-packages (from beautifulsoup4->gdown->nemo_toolkit[nlp]) (2.3.2.post1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (1.3.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (1.50.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (2.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in ./myenv3/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (0.34.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\" in ./myenv3/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (3.8.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in ./myenv3/lib/python3.8/site-packages (from Jinja2>=3.0->Flask>=0.8->flask_restful->nemo_toolkit[nlp]) (2.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./myenv3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (1.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./myenv3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./myenv3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./myenv3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (0.2.8)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./myenv3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./myenv3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./myenv3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./myenv3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./myenv3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./myenv3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (6.0.2)\n",
      "/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/connectionpool.py:999: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pypi.ngc.nvidia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./myenv3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (3.2.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./myenv3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<=1.7.6,>=1.7.0->nemo_toolkit[nlp]) (0.4.8)\n",
      "Building wheels for collected packages: nemo-toolkit, wget, fasttext, gdown, jieba, sacremoses, sentence-transformers, antlr4-python3-runtime, ipadic, pathtools, promise\n",
      "  Building wheel for nemo-toolkit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nemo-toolkit: filename=nemo_toolkit-1.12.0-py3-none-any.whl size=3757058 sha256=d4eb9d7a50ed4c81dd3bf59fc156e34556a9e1cca40ec1036fa9ad873cda11c5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/41/f7/6c/f63337f25b8bbff544d0049f7f85bb0328b5f81e969e47bfa5\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9681 sha256=6974acb7b2cd51ac1c81679a86af9809a3c9c00e9511d81046473614fef4aac6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=4415234 sha256=9af11d39abc2c6ef3767c9a81b006b53601d4bb2ec2c1e81a4a7749f0686ff1a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.3-py3-none-any.whl size=14821 sha256=4f27df49271fe2de3195953799e6de5813f9b6cd923673ad376b508a23e84b09\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/2e/bf/38/838f7a301971b6fa2915069198ae7b48a21833d156ef170960\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=7d2f60ece3eec8c17a7e97e028c93acdca144a816229c227ed5d2e47a5113dd4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/ca/38/d8/dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895255 sha256=9dcbfe3c778be5bed26fab9cd4bb386f13e246e083912a2886bf7a68f51c54b2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125922 sha256=2692141034a784d9f2a43557dacffdb6e81e14d426a015141746fb9ad0da3bbc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=d9da85496aa5570574e1aa8ee94b1cd3bbc0b910ea842d623c61c50c4d899f4f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
      "  Building wheel for ipadic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=2bd7fe8900403f2da17f75d69f472eb9bfdceac081c85ccf9d05726135fc443a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/45/b7/f5/a21e68db846eedcd00d69e37d60bab3f68eb20b1d99cdff652\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=5c901470e19704a01641a773b6ea705712f740e353404a91ff875bd0eeebf19a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21493 sha256=5922cbcd28aa12c906bf4240100b4ad9a113a2509894e14ab836476cd49a05d8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ssi73j69/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built nemo-toolkit wget fasttext gdown jieba sacremoses sentence-transformers antlr4-python3-runtime ipadic pathtools promise\n",
      "Installing collected packages: frozendict, setuptools, llvmlite, numba, protobuf, onnx, ruamel.yaml.clib, ruamel.yaml, joblib, scipy, threadpoolctl, scikit-learn, unidecode, wget, wrapt, jmespath, botocore, s3transfer, boto3, einops, faiss-cpu, fasttext, itsdangerous, click, Flask, aniso8601, pytz, flask-restful, ftfy, gdown, h5py, importlib-resources, antlr4-python3-runtime, pyyaml, omegaconf, hydra-core, ijson, pydantic, inflect, jieba, contourpy, fonttools, kiwisolver, cycler, matplotlib, nltk, opencc, pandas, pangu, pyDeprecate, pytorch-lightning, rapidfuzz, portalocker, colorama, lxml, tabulate, mecab-python3, ipadic, sacrebleu, sacremoses, sentencepiece, tokenizers, transformers, sentence-transformers, sentry-sdk, pathtools, smmap, gitdb, GitPython, promise, docker-pycreds, shortuuid, setproctitle, wandb, braceexpand, webdataset, youtokentome, nemo-toolkit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 44.0.0\n",
      "    Uninstalling setuptools-44.0.0:\n",
      "      Successfully uninstalled setuptools-44.0.0\n",
      "  Attempting uninstall: importlib-resources\n",
      "    Found existing installation: importlib-resources 5.10.0\n",
      "    Uninstalling importlib-resources-5.10.0:\n",
      "      Successfully uninstalled importlib-resources-5.10.0\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.24.0\n",
      "    Uninstalling transformers-4.24.0:\n",
      "      Successfully uninstalled transformers-4.24.0\n",
      "Successfully installed Flask-2.2.2 GitPython-3.1.29 aniso8601-9.0.1 antlr4-python3-runtime-4.9.3 boto3-1.26.8 botocore-1.29.8 braceexpand-0.1.7 click-8.1.3 colorama-0.4.6 contourpy-1.0.6 cycler-0.11.0 docker-pycreds-0.4.0 einops-0.6.0 faiss-cpu-1.7.2 fasttext-0.9.2 flask-restful-0.3.9 fonttools-4.38.0 frozendict-2.3.4 ftfy-6.1.1 gdown-4.5.3 gitdb-4.0.9 h5py-3.7.0 hydra-core-1.2.0 ijson-3.1.4 importlib-resources-5.2.3 inflect-6.0.2 ipadic-1.0.0 itsdangerous-2.1.2 jieba-0.42.1 jmespath-1.0.1 joblib-1.2.0 kiwisolver-1.4.4 llvmlite-0.39.1 lxml-4.9.1 matplotlib-3.6.2 mecab-python3-1.0.5 nemo-toolkit-1.12.0 nltk-3.7 numba-0.56.4 omegaconf-2.2.3 onnx-1.12.0 opencc-1.1.4 pandas-1.5.1 pangu-4.0.6.1 pathtools-0.1.2 portalocker-2.6.0 promise-2.3 protobuf-3.20.3 pyDeprecate-0.3.2 pydantic-1.10.2 pytorch-lightning-1.8.1 pytz-2022.6 pyyaml-5.4.1 rapidfuzz-2.13.2 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 s3transfer-0.6.0 sacrebleu-2.3.1 sacremoses-0.0.53 scikit-learn-1.1.3 scipy-1.9.3 sentence-transformers-2.2.2 sentencepiece-0.1.97 sentry-sdk-1.10.1 setproctitle-1.3.2 setuptools-59.5.0 shortuuid-1.0.11 smmap-5.0.0 tabulate-0.9.0 threadpoolctl-3.1.0 tokenizers-0.12.1 transformers-4.21.2 unidecode-1.3.6 wandb-0.13.5 webdataset-0.1.62 wget-3.2 wrapt-1.14.1 youtokentome-1.0.6\n"
     ]
    }
   ],
   "source": [
    "# install NeMo\n",
    "BRANCH = 'r1.12.0'\n",
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[nlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2332f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-15 16:03:47 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-11-15 16:03:48 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-11-15 16:03:48 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "# 패키지가 잘 설치되었는지 확인\n",
    "\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "import os\n",
    "import wget \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22222e",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93827e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mjk0307/nemo-text-classification/data/auc/dev.tsv\r\n",
      "/home/mjk0307/nemo-text-classification/data/auc/sample_100.tsv\r\n",
      "/home/mjk0307/nemo-text-classification/data/auc/test.tsv\r\n",
      "/home/mjk0307/nemo-text-classification/data/auc/train.tsv\r\n"
     ]
    }
   ],
   "source": [
    "TC3_DATA_DIR = '/home/mjk0307/nemo-text-classification/data/auc'\n",
    "!ls $TC3_DATA_DIR/*.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb01dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "train_nemo_format.tsv sample\n",
      "*****\n",
      "김의원님 이번년도 선거에도 출마하신다고요 허허 벌써 소문이 났습니까 아 이번에도 당선되실 것이 뻔합니다 그때 저희 계약은 유효한거죠 글쎄요 저도 밑지는 장사는 안하는 사람이라 아휴 제가 또 이렇게 눈치가 없네요 이따 나가실 때 비서한테 제주감귤 두박스라고 하면 다 알아듣고 내줄 겁니다 제가 뭘 바라고 그러는 건 아닌데 이렇게 매번 챙겨주시니 감사합니다 제 작은 성의입니다 허허 다음 사업도 예정대로 진행되는 걸로 알겠습니다 물론이죠 김의원님과 저의 번영을 위하여 한 잔 할까요 좋습니다\t2\n",
      "아이스 아메리카노 3잔이랑 티라미슈랑 초코 케이크랑 치즈 케이크 주세요 네 34000원 결제해드릴게요 저기요 저 파워블로거인데요 네 그래서요 뭐 없어요 서비스라거나 저희 가게에선 따로 손님께 서비스가 나가지는 않아서요 다른 곳에선 홍보 좀 해달라고 돈도 안받고 포스팅 부탁하던데 아 네 저흰 괜찮습니다 사장님 태도가 진짜 별로네요 제가 블로그에 글 하나 쓰면 끝인 거 아시죠 그러면 음료는 저희가 서비스로 해드릴게요 처음부터 이러면 서로 좋잖아요\t4\n",
      "김 대리 잠시만 이리 와 봐 네 요즘 속이 너무 답답해서 죽을 것 같아 어떻게 해야 되냐 제가 먹고 있는 약이 있는데 드셔 보세요 좋아보이네 그거 우리 집으로 좀 보내 봐 제가 사서 집으로 보낼테니까 주소 알려 주세요 메신저로 보내지\t1\n",
      "\n",
      "\n",
      "*****\n",
      "dev_nemo_format.tsv sample\n",
      "*****\n",
      "야 너 넷플릭스 보냐 어 넷플릭스 봐 그래 야 그러면 그거 나도 같이 보게 아이디랑 비밀번호 좀 알려줘 그건 좀 그런데 야 같이 나눠 본다고 닳아 닳냐고 새끼야 친구사이에 이런것도 공유해야 진정한 친구 아니겠냐 그러면 나 한달에 5000원만 줘 야 친구사이에 무슨 돈을 달라고해 너무 쪼잔하다 아이디랑 비밀번호 빨리 줘 여 여기\t2\n",
      "야 전화바꿔 당장 고객님 무슨 일이세요 전화바꾸라고 아까 나랑 통화한 상담사 무슨일인지 말씀해주시면 저희측에서 해결을 해드리겠습니다 아니 해결이고 나발이고 자꾸 이상한 소리 하지 말고 아까 나랑 통화한 상담사 바꾸라니까 고객님 이러시면 안되세요 너도 죽고싶어 나한테 잘걸렸다 그럼 아까 그년 대신 너가 해결해\t0\n",
      "야 다리병신 내가 그렇게 부르지 말랬잖아 뭐래 너 설마 개기냐 그런게 아니라 야 애가 정신을 못 차렸네 말대답도 하고 말이야 다리 말고 팔도 병신으로 만들어줄까 그러면 팔다리 병신이 되네 나 같으면 그냥 나가 죽겠다 내 말이 장난 같지 아니야 미안해 잘못했어\t0\n",
      "\n",
      "\n",
      "*****\n",
      "test_nemo_format.tsv sample\n",
      "*****\n",
      "이번 학기에 우리 과 예산 얼마나 남았지 한 100만원 정도 여유 있습니다 그래 야 그러면 그 중에서 한 30만원 정도는 내가 가져가도 모르겠다 선배님 그러시면 제가 곤란해요 새끼야 곤란한건 너 일이고 그건 내가 알 바 아니지 30만원만 좀 내가 가져간다 선배님 새끼야 시끄러워 알아서 잘 채워놔라\t2\n",
      "너네 부모는 어디갔냐 흑흑 저도 몰라요 그래 그럼 너가 대신 돈 갚아야 겠다 제가 무슨 능력이 있어요 그건 너가 알아서 해야지 너도 도망가면 하나 남은 가족인 니 동생 죽여버릴거야 알겠어 네 도망갈 생각은 꿈에도 하지마\t0\n",
      "사장님 저 월급 100만원 더주세요 뭐 지금 우리 가게 수입 뻔히 알면서 그런말이 나와 지금 가게 오는 손님들 다 제 얼굴 보고 오는 손님들이잖아요 저 때문에 가게 유지되고 있는거 아닌가 아니 그래도 그렇지 사정이 있는데 어떻게 100만원이나 올리나 저 안나오면 가게 유지 될 거 같아요 하 그래 내가 어떻게든 마련해서 100만원 올려주겠네\t2\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the tab separated data\n",
    "# \"1\" is \"positive\" and \"0\" is \"negative\"\n",
    "print(\"*****\\ntrain_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/train.tsv\n",
    "print(\"\\n\\n*****\\ndev_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/dev.tsv\n",
    "print(\"\\n\\n*****\\ntest_nemo_format.tsv sample\\n*****\")\n",
    "!head -n 3 $TC3_DATA_DIR/test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c3a82",
   "metadata": {},
   "source": [
    "# Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f692e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
      "# you may not use this file except in compliance with the License.\r\n",
      "# You may obtain a copy of the License at\r\n",
      "#\r\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
      "#\r\n",
      "# Unless required by applicable law or agreed to in writing, software\r\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
      "# See the License for the specific language governing permissions and\r\n",
      "# limitations under the License.\r\n",
      "\r\n",
      "# Config file for text classification with pre-trained BERT models\r\n",
      "\r\n",
      "trainer:\r\n",
      "  devices: 1 # number of GPUs (0 for CPU), or list of the GPUs to use e.g. [0, 1]\r\n",
      "  num_nodes: 1\r\n",
      "  max_epochs: 100\r\n",
      "  max_steps: -1 # precedence over max_epochs\r\n",
      "  accumulate_grad_batches: 1 # accumulates grads every k batches\r\n",
      "  gradient_clip_val: 0.0\r\n",
      "  precision: 32 # Should be set to 16 for O1 and O2 to enable the AMP.\r\n",
      "  accelerator: gpu\r\n",
      "  log_every_n_steps: 1  # Interval of logging.\r\n",
      "  val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations\r\n",
      "  resume_from_checkpoint: null # The path to a checkpoint file to continue the training, restores the whole state including the epoch, step, LR schedulers, apex, etc.\r\n",
      "  num_sanity_val_steps: 0 # number of steps to perform validation steps for sanity check the validation process before starting the training, setting to 0 disables it\r\n",
      "\r\n",
      "  enable_checkpointing: False  # Provided by exp_manager\r\n",
      "  logger: False  # Provided by exp_manager\r\n",
      "\r\n",
      "model:\r\n",
      "  nemo_path: text_classification_model.nemo # filename to save the model and associated artifacts to .nemo file\r\n",
      "  tokenizer:\r\n",
      "      tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece\r\n",
      "      vocab_file: null # path to vocab file\r\n",
      "      tokenizer_model: null # only used if tokenizer is sentencepiece\r\n",
      "      special_tokens: null\r\n",
      "\r\n",
      "  language_model:\r\n",
      "    pretrained_model_name: beomi/KcELECTRA-base\r\n",
      "    lm_checkpoint: null\r\n",
      "    config_file: null # json file, precedence over config\r\n",
      "    config: null\r\n",
      "\r\n",
      "  classifier_head:\r\n",
      "    num_output_layers: 2\r\n",
      "    fc_dropout: 0.1\r\n",
      "\r\n",
      "  class_labels:\r\n",
      "    class_labels_file : null # optional to specify a file containing the list of the labels\r\n",
      "\r\n",
      "  dataset:\r\n",
      "    num_classes: ??? # The number of classes. 0 < Label <num_classes.\r\n",
      "    do_lower_case: false # true for uncased models, false for cased models, will be set automatically if pre-trained tokenizer model is used\r\n",
      "    max_seq_length: 256 # the maximum length BERT supports is 512\r\n",
      "    class_balancing: null # null or 'weighted_loss'. 'weighted_loss' enables the weighted class balancing of the loss, may be used for handling unbalanced classes\r\n",
      "    use_cache: false # uses a cache to store the processed dataset, you may use it for large datasets for speed up\r\n",
      "\r\n",
      "  train_ds:\r\n",
      "    file_path: null\r\n",
      "    batch_size: 64\r\n",
      "    shuffle: true\r\n",
      "    num_samples: -1 # number of samples to be considered, -1 means all the dataset\r\n",
      "    num_workers: 3\r\n",
      "    drop_last: false\r\n",
      "    pin_memory: false\r\n",
      "\r\n",
      "  validation_ds:\r\n",
      "    file_path: null\r\n",
      "    batch_size: 64\r\n",
      "    shuffle: false\r\n",
      "    num_samples: -1 # number of samples to be considered, -1 means all the dataset\r\n",
      "    num_workers: 3\r\n",
      "    drop_last: false\r\n",
      "    pin_memory: false\r\n",
      "\r\n",
      "  test_ds:\r\n",
      "    file_path: null\r\n",
      "    batch_size: 64\r\n",
      "    shuffle: false\r\n",
      "    num_samples: -1 # number of samples to be considered, -1 means all the dataset\r\n",
      "    num_workers: 3\r\n",
      "    drop_last: false\r\n",
      "    pin_memory: false\r\n",
      "\r\n",
      "  optim:\r\n",
      "    name: adam\r\n",
      "    lr: 2e-5\r\n",
      "    # optimizer arguments\r\n",
      "    betas: [0.9, 0.999]\r\n",
      "    weight_decay: 0.01\r\n",
      "\r\n",
      "    # scheduler setup\r\n",
      "    sched:\r\n",
      "      name: WarmupAnnealing\r\n",
      "      # Scheduler params\r\n",
      "      warmup_steps: null\r\n",
      "      warmup_ratio: 0.1\r\n",
      "      last_epoch: -1\r\n",
      "      # pytorch lightning args\r\n",
      "      monitor: val_loss\r\n",
      "      reduce_on_plateau: false\r\n",
      "\r\n",
      "  # List of some sample queries for inference after training is done\r\n",
      "  infer_samples: [\r\n",
      "    'by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .',\r\n",
      "    'director rob marshall went out gunning to make a great one .',\r\n",
      "    'uneasy mishmash of styles and genres .',\r\n",
      "  ]\r\n",
      "\r\n",
      "exp_manager:\r\n",
      "  exp_dir: null  # exp_dir for your experiment, if None, defaults to \"./nemo_experiments\"\r\n",
      "  name: \"TextClassification\"  # The name of your model\r\n",
      "  create_tensorboard_logger: True  # Whether you want exp_manger to create a tb logger\r\n",
      "  create_checkpoint_callback: True  # Whether you want exp_manager to create a modelcheckpoint callback\r\n"
     ]
    }
   ],
   "source": [
    "CONFIG_DIR = \"/home/mjk0307/nemo-text-classification/nemo/examples/nlp/text_classification/conf\"\n",
    "CONFIG_FILE = \"text_classification_config.yaml\"\n",
    "!cat $CONFIG_DIR/$CONFIG_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8bccd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nemo_path: text_classification_model.nemo\n",
      "tokenizer:\n",
      "  tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "  vocab_file: null\n",
      "  tokenizer_model: null\n",
      "  special_tokens: null\n",
      "language_model:\n",
      "  pretrained_model_name: beomi/KcELECTRA-base\n",
      "  lm_checkpoint: null\n",
      "  config_file: null\n",
      "  config: null\n",
      "classifier_head:\n",
      "  num_output_layers: 2\n",
      "  fc_dropout: 0.1\n",
      "class_labels:\n",
      "  class_labels_file: null\n",
      "dataset:\n",
      "  num_classes: ???\n",
      "  do_lower_case: false\n",
      "  max_seq_length: 256\n",
      "  class_balancing: null\n",
      "  use_cache: false\n",
      "train_ds:\n",
      "  file_path: null\n",
      "  batch_size: 64\n",
      "  shuffle: true\n",
      "  num_samples: -1\n",
      "  num_workers: 3\n",
      "  drop_last: false\n",
      "  pin_memory: false\n",
      "validation_ds:\n",
      "  file_path: null\n",
      "  batch_size: 64\n",
      "  shuffle: false\n",
      "  num_samples: -1\n",
      "  num_workers: 3\n",
      "  drop_last: false\n",
      "  pin_memory: false\n",
      "test_ds:\n",
      "  file_path: null\n",
      "  batch_size: 64\n",
      "  shuffle: false\n",
      "  num_samples: -1\n",
      "  num_workers: 3\n",
      "  drop_last: false\n",
      "  pin_memory: false\n",
      "optim:\n",
      "  name: adam\n",
      "  lr: 2.0e-05\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "  weight_decay: 0.01\n",
      "  sched:\n",
      "    name: WarmupAnnealing\n",
      "    warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "infer_samples:\n",
      "- by the end of no such thing the audience , like beatrice , has a watchful affection\n",
      "  for the monster .\n",
      "- director rob marshall went out gunning to make a great one .\n",
      "- uneasy mishmash of styles and genres .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load(CONFIG_DIR + \"/\" + CONFIG_FILE)\n",
    "print(OmegaConf.to_yaml(config.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd59df",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca14615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-14 12:42:25 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-11-14 12:42:27 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-11-14 12:42:27 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-11-14 12:42:27 text_classification_with_bert:91] \n",
      "    Config Params:\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 30\n",
      "      max_steps: -1\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      accelerator: gpu\n",
      "      log_every_n_steps: 1\n",
      "      val_check_interval: 1.0\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "    model:\n",
      "      nemo_path: text_classification_model.nemo\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      language_model:\n",
      "        pretrained_model_name: beomi/KcELECTRA-base\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      class_labels:\n",
      "        class_labels_file: /home/mjk0307/nemo-text-classification/data/auc/class_labels.txt\n",
      "      dataset:\n",
      "        num_classes: 5\n",
      "        do_lower_case: false\n",
      "        max_seq_length: 256\n",
      "        class_balancing: null\n",
      "        use_cache: false\n",
      "      train_ds:\n",
      "        file_path: /home/mjk0307/nemo-text-classification/data/auc/train.tsv\n",
      "        batch_size: 64\n",
      "        shuffle: true\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      validation_ds:\n",
      "        file_path: /home/mjk0307/nemo-text-classification/data/auc/dev.tsv\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      test_ds:\n",
      "        file_path: /home/mjk0307/nemo-text-classification/data/auc/test.tsv\n",
      "        batch_size: 64\n",
      "        shuffle: false\n",
      "        num_samples: -1\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      optim:\n",
      "        name: adam\n",
      "        lr: 2.0e-05\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        weight_decay: 0.01\n",
      "        sched:\n",
      "          name: WarmupAnnealing\n",
      "          warmup_steps: null\n",
      "          warmup_ratio: 0.1\n",
      "          last_epoch: -1\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "      infer_samples:\n",
      "      - by the end of no such thing the audience , like beatrice , has a watchful affection\n",
      "        for the monster .\n",
      "      - director rob marshall went out gunning to make a great one .\n",
      "      - uneasy mishmash of styles and genres .\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: TextClassification\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "[NeMo I 2022-11-14 12:42:27 exp_manager:291] Experiments will be logged at /home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27\n",
      "[NeMo I 2022-11-14 12:42:27 exp_manager:669] TensorboardLogger has been set up\n",
      "[NeMo W 2022-11-14 12:42:27 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2274: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
      "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
      "    \n",
      "[NeMo W 2022-11-14 12:42:27 exp_manager:919] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-11-14 12:42:28 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: beomi/KcELECTRA-base, vocab_file: None, merges_files: None, special_tokens_dict: {}, and use_fast: False\n",
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-11-14 12:42:34 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:120] Read 17919 examples from /home/mjk0307/nemo-text-classification/data/auc/train.tsv.\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:239] example 0: ['사모님', '잘못했어요', '한', '번만', '봐주세요', '음식을', '이따위로', '쓰레기로', '만들어', '놓고', '뭐', '잘못해', '어떤', '부분이', '맛이', '안', '좋으셨는지', '알려주세요', '다', '맘에', '안', '들어', '쓰레기', '같다고', '흑흑', '죄송합니다', '갈비는', '고무줄', '같고', '이게', '뭐야', '퉤', '한', '번만', '더', '기회를', '주세요', '나가', '나가라고', '한', '번만', '더', '눈에', '띄면', '죽여버린다', '네']\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:240] subtokens: [CLS] 사모님 잘못 ##했어요 한 번만 봐주 ##세요 음식 ##을 이따위로 쓰레기 ##로 만들어 놓고 뭐 잘못 ##해 어떤 부분이 맛이 안 좋 ##으셨 ##는지 알려주 ##세요 다 맘에 안 들어 쓰레기 같다고 흑흑 죄송합니다 갈비 ##는 고무줄 같고 이게 뭐야 퉤 한 번만 더 기회를 주세요 나가 나가라 ##고 한 번만 더 눈에 띄 ##면 죽여 ##버린다 네 [SEP]\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:241] input_ids: 2 44998 8131 13422 3777 35363 16771 8007 10929 4053 20550 8121 4096 8238 9744 1565 8131 4025 8375 19253 15772 2434 2895 12657 8111 21086 8007 820 11691 2434 8132 8121 20740 46124 18156 30591 4082 48805 14870 8108 10693 3593 3777 35363 874 14607 10182 8850 16787 4027 3777 35363 874 10389 1197 4172 9653 22413 664 3\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:239] example 1: ['오늘', '오기로', '한', '택배가', '아직도', '안', '와서', '전화', '드렸어요', '언제', '오나요', '죄송합니다', '고객님', '아직', '다', '물건을', '못', '돌려서요', '9시', '넘어야', '될', '것', '같아요', '하루', '종일', '택배', '오기만을', '기다렸는데', '9시까지', '기다리란', '말입니까', '죄송합니다', '고객님', '죄송이고', '뭐고', '빨리', '당장', '가지고', '오세요', '그렇게', '할', '수만', '있음', '저도', '그렇게', '해드리고', '싶네요', '그런데', '그렇게', '안', '된다는', '것', '잘', '아시지', '않습니까', '택배도', '머리를', '써가면서', '돌려야지', '멍청하게', '돌리니까', '이렇게', '배송이', '늦지', '그', '머리로', '어떻게', '사는', '지', '몰라']\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:240] subtokens: [CLS] 오늘 오 ##기로 한 택배 ##가 아직도 안 와서 전화 드렸 ##어요 언제 오 ##나요 죄송합니다 고객 ##님 아직 다 물건 ##을 못 돌려서 ##요 9시 넘어 ##야 될 것 같아요 하루 종일 택배 오 ##기만 ##을 기다렸 ##는데 9시 ##까지 기다리 ##란 말 ##입니까 죄송합니다 고객 ##님 죄송 ##이고 뭐고 빨리 당장 가지고 오세요 그렇게 할 수만 있음 저도 그렇게 해 ##드리고 싶네요 그런데 그렇게 안 된다는 것 잘 아시 ##지 않습니까 택배 ##도 머리를 써 ##가면서 돌려 ##야지 멍청 ##하게 돌리 ##니까 이렇게 배송 ##이 늦 ##지 그 머리로 어떻게 사는 지 몰라 [SEP]\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:241] input_ids: 2 8606 2571 8875 3777 12220 4050 8271 2434 10538 9413 29437 8184 8285 2571 8234 18156 14752 4443 8135 820 10401 4053 1521 45476 4071 16613 8701 4224 961 213 11259 8527 29400 12220 2571 9222 4053 29887 7980 16613 8005 20110 4200 1419 9943 18156 14752 4443 11735 8043 13458 8354 8741 8559 24325 8124 3781 44364 9119 10346 8124 3800 19569 14289 8693 8124 2434 12102 213 2774 14611 4020 22401 12220 4017 17304 2298 11968 9720 8066 8722 8011 18689 8008 8160 19949 4012 791 4020 363 23544 8140 8664 3001 10064 3\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-11-14 12:42:34 text_classification_dataset:244] label: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-14 12:43:12 text_classification_dataset:250] Found 2 out of 17919 sentences with more than 256 subtokens. Truncated long sentences from the end.\n",
      "[NeMo I 2022-11-14 12:43:12 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-11-14 12:43:12 data_preprocessing:406] Min: 23 |                  Max: 256 |                  Mean: 78.44182153021931 |                  Median: 75.0\n",
      "[NeMo I 2022-11-14 12:43:12 data_preprocessing:412] 75 percentile: 91.00\n",
      "[NeMo I 2022-11-14 12:43:12 data_preprocessing:413] 99 percentile: 147.00\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:120] Read 1977 examples from /home/mjk0307/nemo-text-classification/data/auc/dev.tsv.\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:239] example 0: ['야', '너', '넷플릭스', '보냐', '어', '넷플릭스', '봐', '그래', '야', '그러면', '그거', '나도', '같이', '보게', '아이디랑', '비밀번호', '좀', '알려줘', '그건', '좀', '그런데', '야', '같이', '나눠', '본다고', '닳아', '닳냐고', '새끼야', '친구사이에', '이런것도', '공유해야', '진정한', '친구', '아니겠냐', '그러면', '나', '한달에', '5000원만', '줘', '야', '친구사이에', '무슨', '돈을', '달라고해', '너무', '쪼잔하다', '아이디랑', '비밀번호', '빨리', '줘', '여', '여기']\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:240] subtokens: [CLS] 야 너 넷플릭스 보냐 어 넷플릭스 봐 그래 야 그러면 그거 나도 같이 보게 아이디 ##랑 비밀 ##번호 좀 알려 ##줘 그건 좀 그런데 야 같이 나눠 본다고 닳 ##아 닳 ##냐고 새끼야 친구 ##사이 ##에 이런것도 공유 ##해야 진정한 친구 아니 ##겠냐 그러면 나 한달에 5000 ##원 ##만 줘 야 친구 ##사이 ##에 무슨 돈을 달라고 ##해 너무 쪼 ##잔 ##하다 아이디 ##랑 비밀 ##번호 빨리 줘 여 여기 [SEP]\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:241] input_ids: 2 2470 640 38972 19612 2498 38972 1746 8050 2470 9255 8989 8523 8387 13691 15921 4013 14018 15466 2884 9792 4285 9078 2884 8693 2470 8387 10390 43500 833 4037 833 9143 14575 9136 13578 4063 19495 13504 8029 9466 9136 7983 8377 9255 591 18037 16472 4195 4220 2949 2470 9136 13578 4063 8063 9162 12699 4025 8072 3092 4540 8018 15921 4013 14018 15466 8354 2949 2540 8250 3\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:244] label: 2\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:239] example 1: ['야', '전화바꿔', '당장', '고객님', '무슨', '일이세요', '전화바꾸라고', '아까', '나랑', '통화한', '상담사', '무슨일인지', '말씀해주시면', '저희측에서', '해결을', '해드리겠습니다', '아니', '해결이고', '나발이고', '자꾸', '이상한', '소리', '하지', '말고', '아까', '나랑', '통화한', '상담사', '바꾸라니까', '고객님', '이러시면', '안되세요', '너도', '죽고싶어', '나한테', '잘걸렸다', '그럼', '아까', '그년', '대신', '너가', '해결해']\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:240] subtokens: [CLS] 야 전화 ##바꿔 당장 고객 ##님 무슨 일이 ##세요 전화 ##바꾸 ##라고 아까 나랑 통화 ##한 상담 ##사 무슨 ##일 ##인지 말씀 ##해주 ##시면 저희 ##측 ##에서 해결 ##을 해 ##드리 ##겠습니다 아니 해결 ##이고 나발이고 자꾸 이상한 소리 하지 말고 아까 나랑 통화 ##한 상담 ##사 바꾸 ##라니까 고객 ##님 이러 ##시면 안되 ##세요 너도 죽고 ##싶어 나한테 잘 ##걸 ##렸다 그럼 아까 그 ##년 대신 너가 해결 ##해 [SEP]\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:241] input_ids: 2 2470 9413 15941 8741 14752 4443 8063 9050 8007 9413 13820 7987 13509 22135 14292 4069 22722 4029 8063 4129 8154 9587 8346 10299 13117 4734 7979 8646 4053 3800 17819 9503 7983 8646 8043 16748 8920 9410 8178 8097 8246 13509 22135 14292 4069 22722 4029 9486 19987 14752 4443 8332 10299 8122 8007 9145 12889 20865 17244 2774 4369 10009 8150 13509 363 4215 10124 10615 8646 4025 3\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-11-14 12:43:13 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2022-11-14 12:43:18 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-11-14 12:43:18 data_preprocessing:406] Min: 29 |                  Max: 175 |                  Mean: 76.90794132524026 |                  Median: 74.0\n",
      "[NeMo I 2022-11-14 12:43:18 data_preprocessing:412] 75 percentile: 90.00\n",
      "[NeMo I 2022-11-14 12:43:18 data_preprocessing:413] 99 percentile: 142.00\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:120] Read 1978 examples from /home/mjk0307/nemo-text-classification/data/auc/test.tsv.\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:239] example 0: ['이번', '학기에', '우리', '과', '예산', '얼마나', '남았지', '한', '100만원', '정도', '여유', '있습니다', '그래', '야', '그러면', '그', '중에서', '한', '30만원', '정도는', '내가', '가져가도', '모르겠다', '선배님', '그러시면', '제가', '곤란해요', '새끼야', '곤란한건', '너', '일이고', '그건', '내가', '알', '바', '아니지', '30만원만', '좀', '내가', '가져간다', '선배님', '새끼야', '시끄러워', '알아서', '잘', '채워놔라']\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:240] subtokens: [CLS] 이번 학기 ##에 우리 과 예산 얼마나 남았 ##지 한 100만원 정도 여유 있습니다 그래 야 그러면 그 중에서 한 30 ##만원 정도는 내가 가져가 ##도 모르겠다 선배 ##님 그러 ##시면 제가 곤란 ##해요 새끼야 곤란 ##한건 너 일이 ##고 그건 내가 알 바 아니지 30 ##만원 ##만 좀 내가 가져간 ##다 선배 ##님 새끼야 시끄러 ##워 알아서 잘 채워 ##놔라 [SEP]\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:241] input_ids: 2 8183 28190 4063 7992 282 10814 8176 15730 4020 3777 14124 8385 14553 9018 8050 2470 9255 363 22657 3777 8500 8303 13881 8241 30091 4017 10696 17798 4443 8068 10299 11270 22603 8922 14575 22603 9089 640 9050 4027 9078 8241 2438 1620 9346 8500 8303 4220 2884 8241 43474 4058 17798 4443 14575 40884 4275 9260 2774 16562 12744 3\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:244] label: 2\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:238] *** Example ***\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:239] example 1: ['너네', '부모는', '어디갔냐', '흑흑', '저도', '몰라요', '그래', '그럼', '너가', '대신', '돈', '갚아야', '겠다', '제가', '무슨', '능력이', '있어요', '그건', '너가', '알아서', '해야지', '너도', '도망가면', '하나', '남은', '가족인', '니', '동생', '죽여버릴거야', '알겠어', '네', '도망갈', '생각은', '꿈에도', '하지마']\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:240] subtokens: [CLS] 너네 부모는 어디갔냐 흑흑 저도 몰라요 그래 그럼 너가 대신 돈 갚 ##아야 겠다 제가 무슨 능력이 있어요 그건 너가 알아서 해야지 너도 도망가 ##면 하나 남은 가족 ##인 니 동생 죽여 ##버릴 ##거야 알겠 ##어 네 도망 ##갈 생각은 꿈 ##에도 하지마 [SEP]\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:241] input_ids: 2 8786 16385 24177 46124 10346 19965 8050 8150 10615 10124 922 168 8275 41351 11270 8063 11851 10643 9078 10615 9260 8813 9145 33733 4172 8085 10810 8357 4028 802 13322 9653 15668 8629 24167 4006 664 10265 4327 10350 524 8223 10973 3\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-11-14 12:43:18 text_classification_dataset:244] label: 0\n",
      "[NeMo I 2022-11-14 12:43:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-11-14 12:43:22 data_preprocessing:406] Min: 22 |                  Max: 206 |                  Mean: 77.14964610717897 |                  Median: 75.0\n",
      "[NeMo I 2022-11-14 12:43:22 data_preprocessing:412] 75 percentile: 90.00\n",
      "[NeMo I 2022-11-14 12:43:22 data_preprocessing:413] 99 percentile: 137.00\n",
      "[NeMo W 2022-11-14 12:43:22 nlp_overrides:226] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "[NeMo W 2022-11-14 12:43:22 lm_utils:80] beomi/KcELECTRA-base is not in get_pretrained_lm_models_list(include_external=False), will be using AutoModel from HuggingFace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraEncoder: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-11-14 12:43:30 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (ClassificationReport). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n",
      "[NeMo I 2022-11-14 12:43:30 text_classification_with_bert:104] ===========================================================================================\n",
      "[NeMo I 2022-11-14 12:43:30 text_classification_with_bert:105] Starting training...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "[NeMo I 2022-11-14 12:43:32 modelPT:597] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        capturable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        lr: 2e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2022-11-14 12:43:32 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f117a87f910>\" \n",
      "    will be used during training (effective maximum steps = 8400) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    max_steps: 8400\n",
      "    )\n",
      "\n",
      "  | Name                  | Type                 | Params\n",
      "---------------------------------------------------------------\n",
      "0 | loss                  | CrossEntropyLoss     | 0     \n",
      "1 | bert_model            | ElectraEncoder       | 123 M \n",
      "2 | classifier            | SequenceClassifier   | 594 K \n",
      "3 | classification_report | ClassificationReport | 0     \n",
      "---------------------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "498.195   Total estimated model params size (MB)\n",
      "Epoch 0:   0%|                                          | 0/311 [00:00<?, ?it/s][NeMo W 2022-11-14 12:43:32 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:43:32 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:43:32 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 0:  90%|▉| 280/311 [02:42<00:17,  1.72it/s, loss=1.53, v_num=2-27, lr=6.66\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 12:46:15 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:46:15 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:46:15 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 281/311 [02:42<00:17,  1.73it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  91%|▉| 282/311 [02:42<00:16,  1.73it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  91%|▉| 283/311 [02:43<00:16,  1.74it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  91%|▉| 284/311 [02:43<00:15,  1.74it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  92%|▉| 285/311 [02:43<00:14,  1.74it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  92%|▉| 286/311 [02:43<00:14,  1.75it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  92%|▉| 287/311 [02:43<00:13,  1.75it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  93%|▉| 288/311 [02:43<00:13,  1.76it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  94%|▉| 291/311 [02:44<00:11,  1.77it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  94%|▉| 292/311 [02:44<00:10,  1.77it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  94%|▉| 293/311 [02:44<00:10,  1.78it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  95%|▉| 296/311 [02:45<00:08,  1.79it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  95%|▉| 297/311 [02:45<00:07,  1.79it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  96%|▉| 298/311 [02:45<00:07,  1.80it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  96%|▉| 299/311 [02:46<00:06,  1.80it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  97%|▉| 301/311 [02:46<00:05,  1.81it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  97%|▉| 302/311 [02:46<00:04,  1.81it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  97%|▉| 303/311 [02:46<00:04,  1.82it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  98%|▉| 304/311 [02:46<00:03,  1.82it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  98%|▉| 306/311 [02:47<00:02,  1.83it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  99%|▉| 308/311 [02:47<00:01,  1.84it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0:  99%|▉| 309/311 [02:47<00:01,  1.84it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=1.53, v_num=2-27, lr=6.66\u001b[A\n",
      "Epoch 0: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=1.53, v_num=2-27, lr=6.66[NeMo I 2022-11-14 12:46:20 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             71.70      40.43      51.70        376\n",
      "    label_id: 1                                             77.14       6.24      11.54        433\n",
      "    label_id: 2                                              0.00       0.00       0.00        380\n",
      "    label_id: 3                                             27.60      85.52      41.73        366\n",
      "    label_id: 4                                             39.77      56.16      46.56        422\n",
      "    -------------------\n",
      "    micro avg                                               36.87      36.87      36.87       1977\n",
      "    macro avg                                               43.24      37.67      30.31       1977\n",
      "    weighted avg                                            44.13      36.87      30.02       1977\n",
      "    \n",
      "Epoch 0: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=1.53, v_num=2-27, lr=6.66\n",
      "Epoch 0: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=1.53, v_num=2-27, lr=6.66Epoch 0, global step 280: 'val_loss' reached 1.49270 (best 1.49270), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=1.4927-epoch=0.ckpt' as top 3\n",
      "Epoch 1:   0%| | 0/311 [00:00<?, ?it/s, loss=1.53, v_num=2-27, lr=6.66e-6, val_l[NeMo W 2022-11-14 12:46:29 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:46:29 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:46:29 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 1:  90%|▉| 280/311 [02:42<00:18,  1.72it/s, loss=0.787, v_num=2-27, lr=1.3\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 12:49:12 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:49:12 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:49:12 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  91%|▉| 282/311 [02:43<00:16,  1.73it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  91%|▉| 284/311 [02:43<00:15,  1.74it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  92%|▉| 285/311 [02:43<00:14,  1.74it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  92%|▉| 286/311 [02:43<00:14,  1.74it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  92%|▉| 287/311 [02:44<00:13,  1.75it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  94%|▉| 291/311 [02:44<00:11,  1.76it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  94%|▉| 292/311 [02:45<00:10,  1.77it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  95%|▉| 296/311 [02:45<00:08,  1.78it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  95%|▉| 297/311 [02:46<00:07,  1.79it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  96%|▉| 299/311 [02:46<00:06,  1.80it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  97%|▉| 301/311 [02:46<00:05,  1.80it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  97%|▉| 302/311 [02:46<00:04,  1.81it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  98%|▉| 304/311 [02:47<00:03,  1.82it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  98%|▉| 306/311 [02:47<00:02,  1.82it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1:  99%|▉| 309/311 [02:48<00:01,  1.84it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.787, v_num=2-27, lr=1.3\u001b[A\n",
      "Epoch 1: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.787, v_num=2-27, lr=1.3[NeMo I 2022-11-14 12:49:18 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             88.76      81.91      85.20        376\n",
      "    label_id: 1                                             78.25      72.29      75.15        433\n",
      "    label_id: 2                                             79.82      71.84      75.62        380\n",
      "    label_id: 3                                             74.45      92.35      82.44        366\n",
      "    label_id: 4                                             73.73      75.83      74.77        422\n",
      "    -------------------\n",
      "    micro avg                                               78.50      78.50      78.50       1977\n",
      "    macro avg                                               79.00      78.84      78.64       1977\n",
      "    weighted avg                                            78.88      78.50      78.42       1977\n",
      "    \n",
      "Epoch 1: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.787, v_num=2-27, lr=1.3\n",
      "Epoch 1: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.787, v_num=2-27, lr=1.3Epoch 1, global step 560: 'val_loss' reached 0.68094 (best 0.68094), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=0.6809-epoch=1.ckpt' as top 3\n",
      "Epoch 2:   0%| | 0/311 [00:00<?, ?it/s, loss=0.787, v_num=2-27, lr=1.33e-5, val_[NeMo W 2022-11-14 12:49:27 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:49:27 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:49:27 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 2:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.51, v_num=2-27, lr=2e-5\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 12:52:11 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:52:11 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:52:11 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  90%|▉| 281/311 [02:44<00:17,  1.71it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  91%|▉| 284/311 [02:44<00:15,  1.72it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  92%|▉| 286/311 [02:45<00:14,  1.73it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  92%|▉| 287/311 [02:45<00:13,  1.74it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  93%|▉| 290/311 [02:45<00:12,  1.75it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  94%|▉| 291/311 [02:45<00:11,  1.75it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  94%|▉| 292/311 [02:46<00:10,  1.76it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  95%|▉| 294/311 [02:46<00:09,  1.76it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  95%|▉| 296/311 [02:46<00:08,  1.77it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  95%|▉| 297/311 [02:47<00:07,  1.78it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  97%|▉| 301/311 [02:47<00:05,  1.79it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  97%|▉| 302/311 [02:48<00:05,  1.80it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  97%|▉| 303/311 [02:48<00:04,  1.80it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  98%|▉| 306/311 [02:48<00:02,  1.81it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  99%|▉| 308/311 [02:49<00:01,  1.82it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2:  99%|▉| 309/311 [02:49<00:01,  1.82it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.51, v_num=2-27, lr=2e-5\u001b[A\n",
      "Epoch 2: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.51, v_num=2-27, lr=2e-5[NeMo I 2022-11-14 12:52:17 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.76      91.49      89.58        376\n",
      "    label_id: 1                                             89.39      77.83      83.21        433\n",
      "    label_id: 2                                             80.82      88.68      84.57        380\n",
      "    label_id: 3                                             86.58      93.44      89.88        366\n",
      "    label_id: 4                                             84.60      79.38      81.91        422\n",
      "    -------------------\n",
      "    micro avg                                               85.74      85.74      85.74       1977\n",
      "    macro avg                                               85.83      86.17      85.83       1977\n",
      "    weighted avg                                            85.89      85.74      85.64       1977\n",
      "    \n",
      "Epoch 2: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.51, v_num=2-27, lr=2e-5\n",
      "Epoch 2: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.51, v_num=2-27, lr=2e-5Epoch 2, global step 840: 'val_loss' reached 0.44334 (best 0.44334), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=0.4433-epoch=2.ckpt' as top 3\n",
      "Epoch 3:   0%| | 0/311 [00:00<?, ?it/s, loss=0.51, v_num=2-27, lr=2e-5, val_loss[NeMo W 2022-11-14 12:52:26 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:52:26 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:52:26 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 3:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.458, v_num=2-27, lr=1.9\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 12:55:09 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:55:09 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:55:09 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  93%|▉| 288/311 [02:45<00:13,  1.75it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  93%|▉| 290/311 [02:45<00:11,  1.75it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  95%|▉| 294/311 [02:46<00:09,  1.77it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  97%|▉| 303/311 [02:47<00:04,  1.80it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  99%|▉| 308/311 [02:48<00:01,  1.82it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.458, v_num=2-27, lr=1.9\u001b[A\n",
      "Epoch 3: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.458, v_num=2-27, lr=1.9[NeMo I 2022-11-14 12:55:15 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             82.11      95.21      88.18        376\n",
      "    label_id: 1                                             83.82      86.14      84.97        433\n",
      "    label_id: 2                                             86.30      87.89      87.09        380\n",
      "    label_id: 3                                             94.53      80.33      86.85        366\n",
      "    label_id: 4                                             83.67      78.91      81.22        422\n",
      "    -------------------\n",
      "    micro avg                                               85.58      85.58      85.58       1977\n",
      "    macro avg                                               86.09      85.70      85.66       1977\n",
      "    weighted avg                                            85.92      85.58      85.54       1977\n",
      "    \n",
      "Epoch 3: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.458, v_num=2-27, lr=1.9\n",
      "Epoch 3: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.458, v_num=2-27, lr=1.9Epoch 3, global step 1120: 'val_loss' reached 0.44659 (best 0.44334), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=0.4466-epoch=3.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%| | 0/311 [00:00<?, ?it/s, loss=0.458, v_num=2-27, lr=1.93e-5, val_[NeMo W 2022-11-14 12:55:24 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:55:24 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:55:24 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 4:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.348, v_num=2-27, lr=1.8\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 12:58:07 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:58:07 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:58:07 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  90%|▉| 281/311 [02:43<00:17,  1.71it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  93%|▉| 290/311 [02:45<00:11,  1.75it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  95%|▉| 294/311 [02:46<00:09,  1.77it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  97%|▉| 303/311 [02:47<00:04,  1.80it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  99%|▉| 308/311 [02:48<00:01,  1.82it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.348, v_num=2-27, lr=1.8\u001b[A\n",
      "Epoch 4: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.348, v_num=2-27, lr=1.8[NeMo I 2022-11-14 12:58:13 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.06      93.09      89.97        376\n",
      "    label_id: 1                                             84.63      87.76      86.17        433\n",
      "    label_id: 2                                             86.92      89.21      88.05        380\n",
      "    label_id: 3                                             86.81      89.89      88.32        366\n",
      "    label_id: 4                                             89.64      75.83      82.16        422\n",
      "    -------------------\n",
      "    micro avg                                               86.90      86.90      86.90       1977\n",
      "    macro avg                                               87.01      87.16      86.93       1977\n",
      "    weighted avg                                            87.01      86.90      86.80       1977\n",
      "    \n",
      "Epoch 4: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.348, v_num=2-27, lr=1.8\n",
      "Epoch 4: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.348, v_num=2-27, lr=1.8Epoch 4, global step 1400: 'val_loss' reached 0.40665 (best 0.40665), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=0.4067-epoch=4.ckpt' as top 3\n",
      "Epoch 5:   0%| | 0/311 [00:00<?, ?it/s, loss=0.348, v_num=2-27, lr=1.85e-5, val_[NeMo W 2022-11-14 12:58:21 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:58:21 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 12:58:21 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  90%|▉| 280/311 [02:45<00:18,  1.70it/s, loss=0.373, v_num=2-27, lr=1.7\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:01:06 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:01:06 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:01:06 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  90%|▉| 281/311 [02:45<00:17,  1.70it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  91%|▉| 282/311 [02:45<00:17,  1.70it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  91%|▉| 283/311 [02:45<00:16,  1.71it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  91%|▉| 284/311 [02:46<00:15,  1.71it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  92%|▉| 285/311 [02:46<00:15,  1.72it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  92%|▉| 286/311 [02:46<00:14,  1.72it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  92%|▉| 287/311 [02:46<00:13,  1.72it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  93%|▉| 288/311 [02:46<00:13,  1.73it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  93%|▉| 289/311 [02:46<00:12,  1.73it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  93%|▉| 290/311 [02:47<00:12,  1.74it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  94%|▉| 291/311 [02:47<00:11,  1.74it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  94%|▉| 292/311 [02:47<00:10,  1.74it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  94%|▉| 293/311 [02:47<00:10,  1.75it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  95%|▉| 294/311 [02:47<00:09,  1.75it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  95%|▉| 295/311 [02:48<00:09,  1.76it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  95%|▉| 296/311 [02:48<00:08,  1.76it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  95%|▉| 297/311 [02:48<00:07,  1.76it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  96%|▉| 298/311 [02:48<00:07,  1.77it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  96%|▉| 299/311 [02:48<00:06,  1.77it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  96%|▉| 300/311 [02:48<00:06,  1.78it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  97%|▉| 301/311 [02:49<00:05,  1.78it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  97%|▉| 302/311 [02:49<00:05,  1.78it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  97%|▉| 303/311 [02:49<00:04,  1.79it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  98%|▉| 304/311 [02:49<00:03,  1.79it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  98%|▉| 305/311 [02:49<00:03,  1.80it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  98%|▉| 306/311 [02:50<00:02,  1.80it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  99%|▉| 307/311 [02:50<00:02,  1.80it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  99%|▉| 308/311 [02:50<00:01,  1.81it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5:  99%|▉| 309/311 [02:50<00:01,  1.81it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5: 100%|▉| 310/311 [02:50<00:00,  1.82it/s, loss=0.373, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 5: 100%|█| 311/311 [02:50<00:00,  1.82it/s, loss=0.373, v_num=2-27, lr=1.7[NeMo I 2022-11-14 13:01:12 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             90.18      92.82      91.48        376\n",
      "    label_id: 1                                             85.13      85.91      85.52        433\n",
      "    label_id: 2                                             88.98      82.89      85.83        380\n",
      "    label_id: 3                                             78.00      95.90      86.03        366\n",
      "    label_id: 4                                             87.97      72.75      79.64        422\n",
      "    -------------------\n",
      "    micro avg                                               85.69      85.69      85.69       1977\n",
      "    macro avg                                               86.05      86.06      85.70       1977\n",
      "    weighted avg                                            86.12      85.69      85.55       1977\n",
      "    \n",
      "Epoch 5: 100%|█| 311/311 [02:50<00:00,  1.82it/s, loss=0.373, v_num=2-27, lr=1.7\n",
      "Epoch 5: 100%|█| 311/311 [02:50<00:00,  1.82it/s, loss=0.373, v_num=2-27, lr=1.7Epoch 5, global step 1680: 'val_loss' reached 0.44041 (best 0.40665), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=0.4404-epoch=5.ckpt' as top 3\n",
      "Epoch 6:   0%| | 0/311 [00:00<?, ?it/s, loss=0.373, v_num=2-27, lr=1.78e-5, val_[NeMo W 2022-11-14 13:01:20 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:01:20 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:01:20 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 6:  90%|▉| 280/311 [02:43<00:18,  1.72it/s, loss=0.307, v_num=2-27, lr=1.7\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:04:03 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:04:03 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-14 13:04:03 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  91%|▉| 282/311 [02:43<00:16,  1.72it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  92%|▉| 285/311 [02:44<00:14,  1.74it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  93%|▉| 289/311 [02:44<00:12,  1.75it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  93%|▉| 290/311 [02:45<00:11,  1.76it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  95%|▉| 294/311 [02:45<00:09,  1.77it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  95%|▉| 295/311 [02:46<00:09,  1.78it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  96%|▉| 299/311 [02:46<00:06,  1.79it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  98%|▉| 304/311 [02:47<00:03,  1.81it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.307, v_num=2-27, lr=1.7\u001b[A\n",
      "Epoch 6: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.307, v_num=2-27, lr=1.7[NeMo I 2022-11-14 13:04:09 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             84.12      94.41      88.97        376\n",
      "    label_id: 1                                             86.29      84.30      85.28        433\n",
      "    label_id: 2                                             85.05      91.32      88.07        380\n",
      "    label_id: 3                                             92.38      86.07      89.11        366\n",
      "    label_id: 4                                             86.95      78.91      82.73        422\n",
      "    -------------------\n",
      "    micro avg                                               86.75      86.75      86.75       1977\n",
      "    macro avg                                               86.96      87.00      86.83       1977\n",
      "    weighted avg                                            86.91      86.75      86.68       1977\n",
      "    \n",
      "Epoch 6: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.307, v_num=2-27, lr=1.7\n",
      "Epoch 6: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.307, v_num=2-27, lr=1.7Epoch 6, global step 1960: 'val_loss' reached 0.41659 (best 0.40665), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=0.4166-epoch=6.ckpt' as top 3\n",
      "Epoch 7:   0%| | 0/311 [00:00<?, ?it/s, loss=0.307, v_num=2-27, lr=1.7e-5, val_l[NeMo W 2022-11-14 13:04:18 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:04:18 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:04:18 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 7:  90%|▉| 280/311 [02:44<00:18,  1.71it/s, loss=0.309, v_num=2-27, lr=1.6\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:07:02 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:07:02 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:07:02 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  90%|▉| 281/311 [02:44<00:17,  1.71it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  91%|▉| 282/311 [02:44<00:16,  1.71it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  91%|▉| 284/311 [02:45<00:15,  1.72it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  92%|▉| 285/311 [02:45<00:15,  1.73it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  92%|▉| 286/311 [02:45<00:14,  1.73it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  92%|▉| 287/311 [02:45<00:13,  1.73it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  93%|▉| 289/311 [02:45<00:12,  1.74it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  93%|▉| 290/311 [02:46<00:12,  1.75it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  94%|▉| 291/311 [02:46<00:11,  1.75it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  94%|▉| 292/311 [02:46<00:10,  1.75it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  95%|▉| 294/311 [02:46<00:09,  1.76it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  95%|▉| 295/311 [02:47<00:09,  1.77it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  95%|▉| 296/311 [02:47<00:08,  1.77it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  95%|▉| 297/311 [02:47<00:07,  1.77it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  96%|▉| 299/311 [02:47<00:06,  1.78it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  97%|▉| 301/311 [02:48<00:05,  1.79it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  97%|▉| 302/311 [02:48<00:05,  1.79it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  97%|▉| 303/311 [02:48<00:04,  1.80it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  98%|▉| 304/311 [02:48<00:03,  1.80it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  98%|▉| 306/311 [02:49<00:02,  1.81it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  99%|▉| 307/311 [02:49<00:02,  1.81it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  99%|▉| 308/311 [02:49<00:01,  1.82it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7:  99%|▉| 309/311 [02:49<00:01,  1.82it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.309, v_num=2-27, lr=1.6\u001b[A\n",
      "Epoch 7: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.309, v_num=2-27, lr=1.6[NeMo I 2022-11-14 13:07:08 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             86.73      93.88      90.17        376\n",
      "    label_id: 1                                             93.07      77.60      84.63        433\n",
      "    label_id: 2                                             86.92      83.95      85.41        380\n",
      "    label_id: 3                                             76.84      96.99      85.75        366\n",
      "    label_id: 4                                             83.95      75.59      79.55        422\n",
      "    -------------------\n",
      "    micro avg                                               85.08      85.08      85.08       1977\n",
      "    macro avg                                               85.50      85.60      85.10       1977\n",
      "    weighted avg                                            85.73      85.08      84.96       1977\n",
      "    \n",
      "Epoch 7: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.309, v_num=2-27, lr=1.6\n",
      "Epoch 7: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.309, v_num=2-27, lr=1.6Epoch 7, global step 2240: 'val_loss' was not in top 3\n",
      "Epoch 8:   0%| | 0/311 [00:00<?, ?it/s, loss=0.309, v_num=2-27, lr=1.63e-5, val_[NeMo W 2022-11-14 13:07:12 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:07:12 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:07:12 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 8:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.323, v_num=2-27, lr=1.5\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:09:55 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:09:55 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:09:55 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  90%|▉| 281/311 [02:43<00:17,  1.71it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  93%|▉| 290/311 [02:45<00:11,  1.75it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  95%|▉| 294/311 [02:46<00:09,  1.77it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  97%|▉| 302/311 [02:47<00:05,  1.80it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  97%|▉| 303/311 [02:47<00:04,  1.80it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  99%|▉| 308/311 [02:48<00:01,  1.82it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8:  99%|▉| 309/311 [02:49<00:01,  1.83it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.323, v_num=2-27, lr=1.5\u001b[A\n",
      "Epoch 8: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.323, v_num=2-27, lr=1.5[NeMo I 2022-11-14 13:10:01 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             92.74      88.30      90.46        376\n",
      "    label_id: 1                                             86.57      86.37      86.47        433\n",
      "    label_id: 2                                             85.57      90.53      87.98        380\n",
      "    label_id: 3                                             80.58      91.80      85.82        366\n",
      "    label_id: 4                                             85.87      74.88      80.00        422\n",
      "    -------------------\n",
      "    micro avg                                               86.09      86.09      86.09       1977\n",
      "    macro avg                                               86.27      86.38      86.15       1977\n",
      "    weighted avg                                            86.29      86.09      86.02       1977\n",
      "    \n",
      "Epoch 8: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.323, v_num=2-27, lr=1.5\n",
      "Epoch 8: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.323, v_num=2-27, lr=1.5Epoch 8, global step 2520: 'val_loss' reached 0.42592 (best 0.40665), saving model to '/home/mjk0307/nemo-text-classification/nemo_experiments/TextClassification/2022-11-14_12-42-27/checkpoints/TextClassification--val_loss=0.4259-epoch=8.ckpt' as top 3\n",
      "Epoch 9:   0%| | 0/311 [00:00<?, ?it/s, loss=0.323, v_num=2-27, lr=1.56e-5, val_[NeMo W 2022-11-14 13:10:10 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:10:10 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:10:10 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 9:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.37, v_num=2-27, lr=1.48\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:12:53 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:12:53 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:12:53 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  90%|▉| 281/311 [02:44<00:17,  1.71it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  91%|▉| 284/311 [02:44<00:15,  1.72it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  92%|▉| 286/311 [02:45<00:14,  1.73it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  92%|▉| 287/311 [02:45<00:13,  1.74it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  93%|▉| 290/311 [02:45<00:12,  1.75it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  94%|▉| 291/311 [02:45<00:11,  1.75it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  94%|▉| 292/311 [02:46<00:10,  1.76it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  95%|▉| 294/311 [02:46<00:09,  1.76it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  95%|▉| 296/311 [02:46<00:08,  1.77it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  95%|▉| 297/311 [02:47<00:07,  1.78it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  97%|▉| 301/311 [02:47<00:05,  1.79it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  97%|▉| 302/311 [02:48<00:05,  1.80it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  97%|▉| 303/311 [02:48<00:04,  1.80it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  98%|▉| 306/311 [02:48<00:02,  1.81it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  99%|▉| 308/311 [02:49<00:01,  1.82it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9:  99%|▉| 309/311 [02:49<00:01,  1.82it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.37, v_num=2-27, lr=1.48\u001b[A\n",
      "Epoch 9: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.37, v_num=2-27, lr=1.48[NeMo I 2022-11-14 13:12:59 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.09      91.49      89.23        376\n",
      "    label_id: 1                                             90.39      80.37      85.09        433\n",
      "    label_id: 2                                             90.91      76.32      82.98        380\n",
      "    label_id: 3                                             83.41      94.81      88.75        366\n",
      "    label_id: 4                                             76.84      84.12      80.32        422\n",
      "    -------------------\n",
      "    micro avg                                               85.18      85.18      85.18       1977\n",
      "    macro avg                                               85.73      85.42      85.27       1977\n",
      "    weighted avg                                            85.68      85.18      85.13       1977\n",
      "    \n",
      "Epoch 9: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.37, v_num=2-27, lr=1.48\n",
      "Epoch 9: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.37, v_num=2-27, lr=1.48Epoch 9, global step 2800: 'val_loss' was not in top 3\n",
      "Epoch 10:   0%| | 0/311 [00:00<?, ?it/s, loss=0.37, v_num=2-27, lr=1.48e-5, val_[NeMo W 2022-11-14 13:13:04 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:13:04 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:13:04 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 10:  90%|▉| 280/311 [02:42<00:18,  1.72it/s, loss=0.452, v_num=2-27, lr=1.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:15:46 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:15:46 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:15:46 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  91%|▉| 282/311 [02:43<00:16,  1.73it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  91%|▉| 284/311 [02:43<00:15,  1.73it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  92%|▉| 285/311 [02:43<00:14,  1.74it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  92%|▉| 287/311 [02:44<00:13,  1.75it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  94%|▉| 292/311 [02:45<00:10,  1.77it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  95%|▉| 297/311 [02:46<00:07,  1.79it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  96%|▉| 299/311 [02:46<00:06,  1.80it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  97%|▉| 301/311 [02:46<00:05,  1.80it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  97%|▉| 302/311 [02:47<00:04,  1.81it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  98%|▉| 304/311 [02:47<00:03,  1.82it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  98%|▉| 306/311 [02:47<00:02,  1.82it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10:  99%|▉| 309/311 [02:48<00:01,  1.84it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.452, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 10: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.452, v_num=2-27, lr=1.[NeMo I 2022-11-14 13:15:52 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             83.49      92.82      87.91        376\n",
      "    label_id: 1                                             95.27      69.75      80.53        433\n",
      "    label_id: 2                                             88.10      77.89      82.68        380\n",
      "    label_id: 3                                             80.93      95.08      87.44        366\n",
      "    label_id: 4                                             74.79      84.36      79.29        422\n",
      "    -------------------\n",
      "    micro avg                                               83.51      83.51      83.51       1977\n",
      "    macro avg                                               84.52      83.98      83.57       1977\n",
      "    weighted avg                                            84.62      83.51      83.36       1977\n",
      "    \n",
      "Epoch 10: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.452, v_num=2-27, lr=1.\n",
      "Epoch 10: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.452, v_num=2-27, lr=1.Epoch 10, global step 3080: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:   0%| | 0/311 [00:00<?, ?it/s, loss=0.452, v_num=2-27, lr=1.41e-5, val[NeMo W 2022-11-14 13:15:56 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:15:56 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:15:56 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 11:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.309, v_num=2-27, lr=1.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:18:40 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:18:40 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:18:40 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  90%|▉| 281/311 [02:43<00:17,  1.71it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  93%|▉| 290/311 [02:45<00:11,  1.75it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  95%|▉| 294/311 [02:46<00:09,  1.77it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  96%|▉| 298/311 [02:46<00:07,  1.78it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  97%|▉| 303/311 [02:47<00:04,  1.80it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  99%|▉| 308/311 [02:48<00:01,  1.82it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11:  99%|▉| 309/311 [02:49<00:01,  1.83it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.309, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 11: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.309, v_num=2-27, lr=1.[NeMo I 2022-11-14 13:18:46 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             88.68      87.50      88.09        376\n",
      "    label_id: 1                                             83.41      85.91      84.64        433\n",
      "    label_id: 2                                             84.68      85.79      85.23        380\n",
      "    label_id: 3                                             84.80      94.54      89.41        366\n",
      "    label_id: 4                                             86.10      74.88      80.10        422\n",
      "    -------------------\n",
      "    micro avg                                               85.43      85.43      85.43       1977\n",
      "    macro avg                                               85.53      85.72      85.49       1977\n",
      "    weighted avg                                            85.49      85.43      85.32       1977\n",
      "    \n",
      "Epoch 11: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.309, v_num=2-27, lr=1.\n",
      "Epoch 11: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.309, v_num=2-27, lr=1.\u001b[AEpoch 11, global step 3360: 'val_loss' was not in top 3\n",
      "Epoch 12:   0%| | 0/311 [00:00<?, ?it/s, loss=0.309, v_num=2-27, lr=1.33e-5, val[NeMo W 2022-11-14 13:18:50 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:18:50 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-14 13:18:50 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 12:  90%|▉| 280/311 [02:43<00:18,  1.72it/s, loss=0.312, v_num=2-27, lr=1.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:21:33 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:21:33 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:21:33 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  91%|▉| 282/311 [02:43<00:16,  1.72it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  92%|▉| 285/311 [02:44<00:14,  1.74it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  93%|▉| 289/311 [02:44<00:12,  1.75it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  93%|▉| 290/311 [02:45<00:11,  1.76it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  95%|▉| 294/311 [02:45<00:09,  1.77it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  95%|▉| 295/311 [02:46<00:09,  1.78it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  96%|▉| 299/311 [02:46<00:06,  1.79it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  98%|▉| 304/311 [02:47<00:03,  1.81it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 12: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.312, v_num=2-27, lr=1.\u001b[A[NeMo I 2022-11-14 13:21:39 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             90.76      86.17      88.40        376\n",
      "    label_id: 1                                             94.17      70.90      80.90        433\n",
      "    label_id: 2                                             77.46      93.16      84.59        380\n",
      "    label_id: 3                                             87.56      92.35      89.89        366\n",
      "    label_id: 4                                             79.82      85.31      82.47        422\n",
      "    -------------------\n",
      "    micro avg                                               85.13      85.13      85.13       1977\n",
      "    macro avg                                               85.96      85.58      85.25       1977\n",
      "    weighted avg                                            86.02      85.13      85.04       1977\n",
      "    \n",
      "Epoch 12: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.312, v_num=2-27, lr=1.\n",
      "Epoch 12: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.312, v_num=2-27, lr=1.Epoch 12, global step 3640: 'val_loss' was not in top 3\n",
      "Epoch 13:   0%| | 0/311 [00:00<?, ?it/s, loss=0.312, v_num=2-27, lr=1.26e-5, val[NeMo W 2022-11-14 13:21:43 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:21:43 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:21:43 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 13:  90%|▉| 280/311 [02:44<00:18,  1.71it/s, loss=0.337, v_num=2-27, lr=1.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:24:27 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:24:27 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:24:27 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  90%|▉| 281/311 [02:44<00:17,  1.71it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  91%|▉| 282/311 [02:44<00:16,  1.71it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  91%|▉| 284/311 [02:44<00:15,  1.72it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  92%|▉| 285/311 [02:45<00:15,  1.73it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  92%|▉| 286/311 [02:45<00:14,  1.73it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  92%|▉| 287/311 [02:45<00:13,  1.73it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  93%|▉| 289/311 [02:45<00:12,  1.74it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  93%|▉| 290/311 [02:46<00:12,  1.75it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  94%|▉| 291/311 [02:46<00:11,  1.75it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  94%|▉| 292/311 [02:46<00:10,  1.75it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  95%|▉| 294/311 [02:46<00:09,  1.76it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  95%|▉| 295/311 [02:47<00:09,  1.77it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  95%|▉| 296/311 [02:47<00:08,  1.77it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  95%|▉| 297/311 [02:47<00:07,  1.77it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  96%|▉| 299/311 [02:47<00:06,  1.78it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  97%|▉| 301/311 [02:48<00:05,  1.79it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  97%|▉| 302/311 [02:48<00:05,  1.79it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  97%|▉| 303/311 [02:48<00:04,  1.80it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  98%|▉| 304/311 [02:48<00:03,  1.80it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  98%|▉| 306/311 [02:49<00:02,  1.81it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  99%|▉| 307/311 [02:49<00:02,  1.81it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  99%|▉| 308/311 [02:49<00:01,  1.82it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13:  99%|▉| 309/311 [02:49<00:01,  1.82it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.337, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 13: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.337, v_num=2-27, lr=1.[NeMo I 2022-11-14 13:24:33 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             82.28      93.88      87.70        376\n",
      "    label_id: 1                                             91.01      77.14      83.50        433\n",
      "    label_id: 2                                             84.95      87.63      86.27        380\n",
      "    label_id: 3                                             85.75      92.08      88.80        366\n",
      "    label_id: 4                                             84.60      79.38      81.91        422\n",
      "    -------------------\n",
      "    micro avg                                               85.58      85.58      85.58       1977\n",
      "    macro avg                                               85.72      86.02      85.64       1977\n",
      "    weighted avg                                            85.84      85.58      85.47       1977\n",
      "    \n",
      "Epoch 13: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.337, v_num=2-27, lr=1.\n",
      "Epoch 13: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.337, v_num=2-27, lr=1.Epoch 13, global step 3920: 'val_loss' was not in top 3\n",
      "Epoch 14:   0%| | 0/311 [00:00<?, ?it/s, loss=0.337, v_num=2-27, lr=1.19e-5, val[NeMo W 2022-11-14 13:24:37 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:24:37 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:24:37 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 14:  90%|▉| 280/311 [02:42<00:18,  1.72it/s, loss=0.327, v_num=2-27, lr=1.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:27:20 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:27:20 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:27:20 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  91%|▉| 282/311 [02:43<00:16,  1.72it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  91%|▉| 284/311 [02:43<00:15,  1.73it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  92%|▉| 285/311 [02:44<00:14,  1.74it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  92%|▉| 287/311 [02:44<00:13,  1.75it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  93%|▉| 289/311 [02:44<00:12,  1.75it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  94%|▉| 292/311 [02:45<00:10,  1.77it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  95%|▉| 294/311 [02:45<00:09,  1.77it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  95%|▉| 297/311 [02:46<00:07,  1.79it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  96%|▉| 299/311 [02:46<00:06,  1.79it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  97%|▉| 302/311 [02:47<00:04,  1.81it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  98%|▉| 304/311 [02:47<00:03,  1.81it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  98%|▉| 306/311 [02:47<00:02,  1.82it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  99%|▉| 307/311 [02:48<00:02,  1.83it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.327, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 14: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.327, v_num=2-27, lr=1.[NeMo I 2022-11-14 13:27:26 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             91.81      83.51      87.47        376\n",
      "    label_id: 1                                             81.55      87.76      84.54        433\n",
      "    label_id: 2                                             91.88      74.47      82.27        380\n",
      "    label_id: 3                                             79.14      95.36      86.49        366\n",
      "    label_id: 4                                             80.00      79.62      79.81        422\n",
      "    -------------------\n",
      "    micro avg                                               84.07      84.07      84.07       1977\n",
      "    macro avg                                               84.88      84.14      84.11       1977\n",
      "    weighted avg                                            84.71      84.07      84.01       1977\n",
      "    \n",
      "Epoch 14: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.327, v_num=2-27, lr=1.\n",
      "Epoch 14: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.327, v_num=2-27, lr=1.Epoch 14, global step 4200: 'val_loss' was not in top 3\n",
      "Epoch 15:   0%| | 0/311 [00:00<?, ?it/s, loss=0.327, v_num=2-27, lr=1.11e-5, val[NeMo W 2022-11-14 13:27:30 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:27:30 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:27:30 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 15:  90%|▉| 280/311 [02:43<00:18,  1.72it/s, loss=0.31, v_num=2-27, lr=1.0\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:30:14 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:30:14 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:30:14 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  91%|▉| 282/311 [02:43<00:16,  1.72it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  92%|▉| 285/311 [02:44<00:14,  1.73it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  93%|▉| 289/311 [02:44<00:12,  1.75it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  93%|▉| 290/311 [02:45<00:11,  1.76it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  95%|▉| 294/311 [02:45<00:09,  1.77it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  95%|▉| 295/311 [02:46<00:09,  1.78it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  96%|▉| 299/311 [02:46<00:06,  1.79it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  96%|▉| 300/311 [02:47<00:06,  1.80it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  98%|▉| 304/311 [02:47<00:03,  1.81it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A\n",
      "Epoch 15: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.31, v_num=2-27, lr=1.0\u001b[A[NeMo I 2022-11-14 13:30:19 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             94.23      78.19      85.47        376\n",
      "    label_id: 1                                             72.79      93.30      81.78        433\n",
      "    label_id: 2                                             90.85      73.16      81.05        380\n",
      "    label_id: 3                                             89.42      87.70      88.55        366\n",
      "    label_id: 4                                             78.88      83.18      80.97        422\n",
      "    -------------------\n",
      "    micro avg                                               83.36      83.36      83.36       1977\n",
      "    macro avg                                               85.23      83.11      83.56       1977\n",
      "    weighted avg                                            84.72      83.36      83.42       1977\n",
      "    \n",
      "Epoch 15: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.31, v_num=2-27, lr=1.0\n",
      "Epoch 15: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.31, v_num=2-27, lr=1.0Epoch 15, global step 4480: 'val_loss' was not in top 3\n",
      "Epoch 16:   0%| | 0/311 [00:00<?, ?it/s, loss=0.31, v_num=2-27, lr=1.04e-5, val_[NeMo W 2022-11-14 13:30:24 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:30:24 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:30:24 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 16:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.371, v_num=2-27, lr=9.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:33:07 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:33:07 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:33:07 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  90%|▉| 281/311 [02:43<00:17,  1.71it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  93%|▉| 290/311 [02:45<00:11,  1.75it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  95%|▉| 294/311 [02:46<00:09,  1.77it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  96%|▉| 298/311 [02:46<00:07,  1.78it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  97%|▉| 303/311 [02:47<00:04,  1.80it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  99%|▉| 308/311 [02:48<00:01,  1.82it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16:  99%|▉| 309/311 [02:49<00:01,  1.83it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.371, v_num=2-27, lr=9.\u001b[A\n",
      "Epoch 16: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.371, v_num=2-27, lr=9.[NeMo I 2022-11-14 13:33:13 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             86.75      88.83      87.78        376\n",
      "    label_id: 1                                             91.83      77.83      84.25        433\n",
      "    label_id: 2                                             82.57      89.74      86.00        380\n",
      "    label_id: 3                                             87.09      93.99      90.41        366\n",
      "    label_id: 4                                             83.45      82.46      82.96        422\n",
      "    -------------------\n",
      "    micro avg                                               86.19      86.19      86.19       1977\n",
      "    macro avg                                               86.34      86.57      86.28       1977\n",
      "    weighted avg                                            86.42      86.19      86.12       1977\n",
      "    \n",
      "Epoch 16: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.371, v_num=2-27, lr=9.\n",
      "Epoch 16: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.371, v_num=2-27, lr=9.Epoch 16, global step 4760: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:   0%| | 0/311 [00:00<?, ?it/s, loss=0.371, v_num=2-27, lr=9.63e-6, val[NeMo W 2022-11-14 13:33:17 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:33:17 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:33:17 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 17:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.285, v_num=2-27, lr=8.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:36:01 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:36:01 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:36:01 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  90%|▉| 281/311 [02:44<00:17,  1.71it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  91%|▉| 282/311 [02:44<00:16,  1.71it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  91%|▉| 284/311 [02:44<00:15,  1.72it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  92%|▉| 286/311 [02:45<00:14,  1.73it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  92%|▉| 287/311 [02:45<00:13,  1.74it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  93%|▉| 289/311 [02:45<00:12,  1.74it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  93%|▉| 290/311 [02:45<00:12,  1.75it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  94%|▉| 291/311 [02:46<00:11,  1.75it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  94%|▉| 292/311 [02:46<00:10,  1.76it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  95%|▉| 294/311 [02:46<00:09,  1.76it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  95%|▉| 296/311 [02:47<00:08,  1.77it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  95%|▉| 297/311 [02:47<00:07,  1.78it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  96%|▉| 299/311 [02:47<00:06,  1.78it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  97%|▉| 301/311 [02:47<00:05,  1.79it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  97%|▉| 302/311 [02:48<00:05,  1.80it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  97%|▉| 303/311 [02:48<00:04,  1.80it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  98%|▉| 304/311 [02:48<00:03,  1.80it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  98%|▉| 306/311 [02:48<00:02,  1.81it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  99%|▉| 307/311 [02:49<00:02,  1.82it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  99%|▉| 308/311 [02:49<00:01,  1.82it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17:  99%|▉| 309/311 [02:49<00:01,  1.82it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 17: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.285, v_num=2-27, lr=8.[NeMo I 2022-11-14 13:36:07 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             79.91      93.09      86.00        376\n",
      "    label_id: 1                                             91.15      78.52      84.37        433\n",
      "    label_id: 2                                             86.56      84.74      85.64        380\n",
      "    label_id: 3                                             84.24      93.44      88.60        366\n",
      "    label_id: 4                                             83.76      77.01      80.25        422\n",
      "    -------------------\n",
      "    micro avg                                               84.93      84.93      84.93       1977\n",
      "    macro avg                                               85.12      85.36      84.97       1977\n",
      "    weighted avg                                            85.27      84.93      84.83       1977\n",
      "    \n",
      "Epoch 17: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.285, v_num=2-27, lr=8.\n",
      "Epoch 17: 100%|█| 311/311 [02:49<00:00,  1.83it/s, loss=0.285, v_num=2-27, lr=8.Epoch 17, global step 5040: 'val_loss' was not in top 3\n",
      "Epoch 18:   0%| | 0/311 [00:00<?, ?it/s, loss=0.285, v_num=2-27, lr=8.89e-6, val[NeMo W 2022-11-14 13:36:11 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:36:11 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:36:11 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  90%|▉| 280/311 [02:42<00:17,  1.72it/s, loss=0.285, v_num=2-27, lr=8.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:38:53 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:38:53 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:38:53 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  90%|▉| 281/311 [02:42<00:17,  1.73it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  91%|▉| 282/311 [02:43<00:16,  1.73it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  91%|▉| 284/311 [02:43<00:15,  1.74it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  92%|▉| 285/311 [02:43<00:14,  1.74it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  92%|▉| 286/311 [02:43<00:14,  1.75it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  92%|▉| 287/311 [02:43<00:13,  1.75it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  93%|▉| 288/311 [02:44<00:13,  1.76it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  94%|▉| 291/311 [02:44<00:11,  1.77it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  94%|▉| 292/311 [02:44<00:10,  1.77it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  94%|▉| 293/311 [02:44<00:10,  1.78it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  95%|▉| 296/311 [02:45<00:08,  1.79it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  95%|▉| 297/311 [02:45<00:07,  1.79it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  96%|▉| 298/311 [02:45<00:07,  1.80it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  96%|▉| 299/311 [02:46<00:06,  1.80it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  97%|▉| 301/311 [02:46<00:05,  1.81it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  97%|▉| 302/311 [02:46<00:04,  1.81it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  97%|▉| 303/311 [02:46<00:04,  1.82it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  98%|▉| 304/311 [02:46<00:03,  1.82it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  98%|▉| 306/311 [02:47<00:02,  1.83it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  99%|▉| 308/311 [02:47<00:01,  1.84it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18:  99%|▉| 309/311 [02:47<00:01,  1.84it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.285, v_num=2-27, lr=8.\u001b[A\n",
      "Epoch 18: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.285, v_num=2-27, lr=8.[NeMo I 2022-11-14 13:38:59 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.77      87.77      87.77        376\n",
      "    label_id: 1                                             93.60      74.36      82.88        433\n",
      "    label_id: 2                                             84.79      86.58      85.68        380\n",
      "    label_id: 3                                             80.32      94.81      86.97        366\n",
      "    label_id: 4                                             78.95      81.75      80.33        422\n",
      "    -------------------\n",
      "    micro avg                                               84.62      84.62      84.62       1977\n",
      "    macro avg                                               85.09      85.05      84.72       1977\n",
      "    weighted avg                                            85.21      84.62      84.56       1977\n",
      "    \n",
      "Epoch 18: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.285, v_num=2-27, lr=8.\n",
      "Epoch 18: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.285, v_num=2-27, lr=8.Epoch 18, global step 5320: 'val_loss' was not in top 3\n",
      "Epoch 19:   0%| | 0/311 [00:00<?, ?it/s, loss=0.285, v_num=2-27, lr=8.15e-6, val[NeMo W 2022-11-14 13:39:03 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:39:03 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:39:03 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 19:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.329, v_num=2-27, lr=7.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:41:47 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:41:47 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-14 13:41:47 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  91%|▉| 282/311 [02:44<00:16,  1.72it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  92%|▉| 285/311 [02:44<00:15,  1.73it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  93%|▉| 288/311 [02:45<00:13,  1.75it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  93%|▉| 290/311 [02:45<00:11,  1.75it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  95%|▉| 294/311 [02:46<00:09,  1.77it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  96%|▉| 299/311 [02:47<00:06,  1.79it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  98%|▉| 304/311 [02:48<00:03,  1.81it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  99%|▉| 308/311 [02:48<00:01,  1.82it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.329, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 19: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.329, v_num=2-27, lr=7.[NeMo I 2022-11-14 13:41:53 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.63      88.56      88.10        376\n",
      "    label_id: 1                                             87.41      84.99      86.18        433\n",
      "    label_id: 2                                             85.49      86.84      86.16        380\n",
      "    label_id: 3                                             89.49      90.71      90.09        366\n",
      "    label_id: 4                                             83.77      83.18      83.47        422\n",
      "    -------------------\n",
      "    micro avg                                               86.70      86.70      86.70       1977\n",
      "    macro avg                                               86.76      86.86      86.80       1977\n",
      "    weighted avg                                            86.69      86.70      86.69       1977\n",
      "    \n",
      "Epoch 19: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.329, v_num=2-27, lr=7.\n",
      "Epoch 19: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.329, v_num=2-27, lr=7.Epoch 19, global step 5600: 'val_loss' was not in top 3\n",
      "Epoch 20:   0%| | 0/311 [00:00<?, ?it/s, loss=0.329, v_num=2-27, lr=7.41e-6, val[NeMo W 2022-11-14 13:41:57 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:41:57 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:41:57 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 20:  90%|▉| 280/311 [02:42<00:17,  1.73it/s, loss=0.271, v_num=2-27, lr=6.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:44:39 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:44:39 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:44:39 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  90%|▉| 281/311 [02:42<00:17,  1.73it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  91%|▉| 282/311 [02:42<00:16,  1.73it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  91%|▉| 283/311 [02:42<00:16,  1.74it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  91%|▉| 284/311 [02:43<00:15,  1.74it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  92%|▉| 285/311 [02:43<00:14,  1.75it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  92%|▉| 286/311 [02:43<00:14,  1.75it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  92%|▉| 287/311 [02:43<00:13,  1.76it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  93%|▉| 288/311 [02:43<00:13,  1.76it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  93%|▉| 289/311 [02:43<00:12,  1.76it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  93%|▉| 290/311 [02:44<00:11,  1.77it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  94%|▉| 291/311 [02:44<00:11,  1.77it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  94%|▉| 292/311 [02:44<00:10,  1.78it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  94%|▉| 293/311 [02:44<00:10,  1.78it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  95%|▉| 294/311 [02:44<00:09,  1.78it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  95%|▉| 295/311 [02:45<00:08,  1.79it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  95%|▉| 296/311 [02:45<00:08,  1.79it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  95%|▉| 297/311 [02:45<00:07,  1.80it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  96%|▉| 298/311 [02:45<00:07,  1.80it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  96%|▉| 299/311 [02:45<00:06,  1.80it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  96%|▉| 300/311 [02:45<00:06,  1.81it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  97%|▉| 301/311 [02:46<00:05,  1.81it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  97%|▉| 302/311 [02:46<00:04,  1.82it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  97%|▉| 303/311 [02:46<00:04,  1.82it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  98%|▉| 304/311 [02:46<00:03,  1.82it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  98%|▉| 305/311 [02:46<00:03,  1.83it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  98%|▉| 306/311 [02:47<00:02,  1.83it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  99%|▉| 307/311 [02:47<00:02,  1.84it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  99%|▉| 308/311 [02:47<00:01,  1.84it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20:  99%|▉| 309/311 [02:47<00:01,  1.84it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20: 100%|▉| 310/311 [02:47<00:00,  1.85it/s, loss=0.271, v_num=2-27, lr=6.\u001b[A\n",
      "Epoch 20: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.271, v_num=2-27, lr=6.[NeMo I 2022-11-14 13:44:45 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             86.45      89.89      88.14        376\n",
      "    label_id: 1                                             95.32      75.29      84.13        433\n",
      "    label_id: 2                                             80.65      91.05      85.54        380\n",
      "    label_id: 3                                             82.86      95.08      88.55        366\n",
      "    label_id: 4                                             83.80      78.44      81.03        422\n",
      "    -------------------\n",
      "    micro avg                                               85.43      85.43      85.43       1977\n",
      "    macro avg                                               85.81      85.95      85.48       1977\n",
      "    weighted avg                                            86.05      85.43      85.32       1977\n",
      "    \n",
      "Epoch 20: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.271, v_num=2-27, lr=6.\n",
      "Epoch 20: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.271, v_num=2-27, lr=6.Epoch 20, global step 5880: 'val_loss' was not in top 3\n",
      "Epoch 21:   0%| | 0/311 [00:00<?, ?it/s, loss=0.271, v_num=2-27, lr=6.67e-6, val[NeMo W 2022-11-14 13:44:49 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:44:49 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:44:49 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 21:  90%|▉| 280/311 [02:44<00:18,  1.70it/s, loss=0.261, v_num=2-27, lr=5.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:47:34 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:47:34 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:47:34 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  90%|▉| 281/311 [02:44<00:17,  1.71it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  91%|▉| 282/311 [02:44<00:16,  1.71it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  91%|▉| 283/311 [02:45<00:16,  1.71it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  91%|▉| 284/311 [02:45<00:15,  1.72it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  92%|▉| 285/311 [02:45<00:15,  1.72it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  92%|▉| 286/311 [02:45<00:14,  1.73it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  92%|▉| 287/311 [02:45<00:13,  1.73it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  93%|▉| 289/311 [02:46<00:12,  1.74it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  93%|▉| 290/311 [02:46<00:12,  1.74it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  94%|▉| 291/311 [02:46<00:11,  1.75it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  94%|▉| 292/311 [02:46<00:10,  1.75it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  95%|▉| 294/311 [02:47<00:09,  1.76it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  95%|▉| 295/311 [02:47<00:09,  1.76it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  95%|▉| 296/311 [02:47<00:08,  1.77it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  95%|▉| 297/311 [02:47<00:07,  1.77it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  96%|▉| 299/311 [02:48<00:06,  1.78it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  96%|▉| 300/311 [02:48<00:06,  1.78it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  97%|▉| 301/311 [02:48<00:05,  1.79it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  97%|▉| 302/311 [02:48<00:05,  1.79it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  97%|▉| 303/311 [02:48<00:04,  1.80it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  98%|▉| 304/311 [02:48<00:03,  1.80it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  98%|▉| 305/311 [02:49<00:03,  1.80it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  98%|▉| 306/311 [02:49<00:02,  1.81it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  99%|▉| 307/311 [02:49<00:02,  1.81it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  99%|▉| 308/311 [02:49<00:01,  1.82it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21:  99%|▉| 309/311 [02:49<00:01,  1.82it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21: 100%|▉| 310/311 [02:50<00:00,  1.82it/s, loss=0.261, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 21: 100%|█| 311/311 [02:50<00:00,  1.83it/s, loss=0.261, v_num=2-27, lr=5.[NeMo I 2022-11-14 13:47:39 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             86.60      89.36      87.96        376\n",
      "    label_id: 1                                             83.33      85.45      84.38        433\n",
      "    label_id: 2                                             87.78      83.16      85.41        380\n",
      "    label_id: 3                                             83.00      92.08      87.31        366\n",
      "    label_id: 4                                             85.49      76.78      80.90        422\n",
      "    -------------------\n",
      "    micro avg                                               85.13      85.13      85.13       1977\n",
      "    macro avg                                               85.24      85.36      85.19       1977\n",
      "    weighted avg                                            85.21      85.13      85.06       1977\n",
      "    \n",
      "Epoch 21: 100%|█| 311/311 [02:50<00:00,  1.83it/s, loss=0.261, v_num=2-27, lr=5.\n",
      "Epoch 21: 100%|█| 311/311 [02:50<00:00,  1.83it/s, loss=0.261, v_num=2-27, lr=5.Epoch 21, global step 6160: 'val_loss' was not in top 3\n",
      "Epoch 22:   0%| | 0/311 [00:00<?, ?it/s, loss=0.261, v_num=2-27, lr=5.93e-6, val[NeMo W 2022-11-14 13:47:44 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:47:44 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:47:44 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 22:  90%|▉| 280/311 [02:42<00:17,  1.73it/s, loss=0.222, v_num=2-27, lr=5.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:50:26 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:50:26 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:50:26 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  90%|▉| 281/311 [02:42<00:17,  1.73it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  91%|▉| 282/311 [02:42<00:16,  1.73it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  91%|▉| 283/311 [02:43<00:16,  1.74it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  91%|▉| 284/311 [02:43<00:15,  1.74it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  92%|▉| 285/311 [02:43<00:14,  1.75it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  92%|▉| 286/311 [02:43<00:14,  1.75it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  92%|▉| 287/311 [02:43<00:13,  1.75it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  93%|▉| 288/311 [02:43<00:13,  1.76it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  93%|▉| 290/311 [02:44<00:11,  1.77it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  94%|▉| 291/311 [02:44<00:11,  1.77it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  94%|▉| 292/311 [02:44<00:10,  1.77it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  94%|▉| 293/311 [02:44<00:10,  1.78it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  95%|▉| 295/311 [02:45<00:08,  1.79it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  95%|▉| 296/311 [02:45<00:08,  1.79it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  95%|▉| 297/311 [02:45<00:07,  1.79it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  96%|▉| 298/311 [02:45<00:07,  1.80it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  96%|▉| 299/311 [02:45<00:06,  1.80it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  96%|▉| 300/311 [02:46<00:06,  1.81it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  97%|▉| 301/311 [02:46<00:05,  1.81it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  97%|▉| 302/311 [02:46<00:04,  1.81it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  97%|▉| 303/311 [02:46<00:04,  1.82it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  98%|▉| 304/311 [02:46<00:03,  1.82it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  98%|▉| 305/311 [02:47<00:03,  1.83it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  98%|▉| 306/311 [02:47<00:02,  1.83it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  99%|▉| 308/311 [02:47<00:01,  1.84it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22:  99%|▉| 309/311 [02:47<00:01,  1.84it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22: 100%|▉| 310/311 [02:47<00:00,  1.85it/s, loss=0.222, v_num=2-27, lr=5.\u001b[A\n",
      "Epoch 22: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.222, v_num=2-27, lr=5.[NeMo I 2022-11-14 13:50:32 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             87.87      86.70      87.28        376\n",
      "    label_id: 1                                             90.91      80.83      85.57        433\n",
      "    label_id: 2                                             84.21      84.21      84.21        380\n",
      "    label_id: 3                                             80.00      93.99      86.43        366\n",
      "    label_id: 4                                             81.51      79.38      80.43        422\n",
      "    -------------------\n",
      "    micro avg                                               84.72      84.72      84.72       1977\n",
      "    macro avg                                               84.90      85.02      84.79       1977\n",
      "    weighted avg                                            85.02      84.72      84.70       1977\n",
      "    \n",
      "Epoch 22: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.222, v_num=2-27, lr=5.\n",
      "Epoch 22: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.222, v_num=2-27, lr=5.Epoch 22, global step 6440: 'val_loss' was not in top 3\n",
      "Epoch 23:   0%| | 0/311 [00:00<?, ?it/s, loss=0.222, v_num=2-27, lr=5.19e-6, val[NeMo W 2022-11-14 13:50:36 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:50:36 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:50:36 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 23:  90%|▉| 280/311 [02:44<00:18,  1.70it/s, loss=0.243, v_num=2-27, lr=4.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:53:21 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:53:21 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:53:21 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  90%|▉| 281/311 [02:45<00:17,  1.70it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  91%|▉| 282/311 [02:45<00:17,  1.70it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  91%|▉| 283/311 [02:45<00:16,  1.71it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  91%|▉| 284/311 [02:45<00:15,  1.71it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  92%|▉| 285/311 [02:46<00:15,  1.72it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  92%|▉| 286/311 [02:46<00:14,  1.72it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  92%|▉| 287/311 [02:46<00:13,  1.73it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  93%|▉| 288/311 [02:46<00:13,  1.73it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  93%|▉| 289/311 [02:46<00:12,  1.73it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  93%|▉| 290/311 [02:46<00:12,  1.74it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  94%|▉| 291/311 [02:47<00:11,  1.74it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  94%|▉| 292/311 [02:47<00:10,  1.74it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  94%|▉| 293/311 [02:47<00:10,  1.75it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  95%|▉| 294/311 [02:47<00:09,  1.75it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  95%|▉| 295/311 [02:47<00:09,  1.76it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  95%|▉| 296/311 [02:48<00:08,  1.76it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  95%|▉| 297/311 [02:48<00:07,  1.77it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  96%|▉| 298/311 [02:48<00:07,  1.77it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  96%|▉| 299/311 [02:48<00:06,  1.77it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  96%|▉| 300/311 [02:48<00:06,  1.78it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  97%|▉| 301/311 [02:49<00:05,  1.78it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  97%|▉| 302/311 [02:49<00:05,  1.78it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  97%|▉| 303/311 [02:49<00:04,  1.79it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  98%|▉| 304/311 [02:49<00:03,  1.79it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  98%|▉| 305/311 [02:49<00:03,  1.80it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  98%|▉| 306/311 [02:49<00:02,  1.80it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  99%|▉| 307/311 [02:50<00:02,  1.80it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  99%|▉| 308/311 [02:50<00:01,  1.81it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23:  99%|▉| 309/311 [02:50<00:01,  1.81it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23: 100%|▉| 310/311 [02:50<00:00,  1.82it/s, loss=0.243, v_num=2-27, lr=4.\u001b[A\n",
      "Epoch 23: 100%|█| 311/311 [02:50<00:00,  1.82it/s, loss=0.243, v_num=2-27, lr=4.[NeMo I 2022-11-14 13:53:27 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             91.04      83.78      87.26        376\n",
      "    label_id: 1                                             75.95      92.61      83.45        433\n",
      "    label_id: 2                                             89.44      80.26      84.60        380\n",
      "    label_id: 3                                             90.29      86.34      88.27        366\n",
      "    label_id: 4                                             81.80      79.86      80.82        422\n",
      "    -------------------\n",
      "    micro avg                                               84.67      84.67      84.67       1977\n",
      "    macro avg                                               85.70      84.57      84.88       1977\n",
      "    weighted avg                                            85.31      84.67      84.73       1977\n",
      "    \n",
      "Epoch 23: 100%|█| 311/311 [02:50<00:00,  1.82it/s, loss=0.243, v_num=2-27, lr=4.\n",
      "Epoch 23: 100%|█| 311/311 [02:50<00:00,  1.82it/s, loss=0.243, v_num=2-27, lr=4.Epoch 23, global step 6720: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:   0%| | 0/311 [00:00<?, ?it/s, loss=0.243, v_num=2-27, lr=4.45e-6, val[NeMo W 2022-11-14 13:53:31 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:53:31 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:53:31 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 24:  90%|▉| 280/311 [02:44<00:18,  1.70it/s, loss=0.26, v_num=2-27, lr=3.7\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:56:15 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:56:15 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:56:15 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  90%|▉| 281/311 [02:44<00:17,  1.71it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  91%|▉| 282/311 [02:44<00:16,  1.71it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  91%|▉| 283/311 [02:45<00:16,  1.71it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  91%|▉| 284/311 [02:45<00:15,  1.72it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  92%|▉| 285/311 [02:45<00:15,  1.72it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  92%|▉| 286/311 [02:45<00:14,  1.73it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  92%|▉| 287/311 [02:45<00:13,  1.73it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  93%|▉| 288/311 [02:45<00:13,  1.74it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  93%|▉| 289/311 [02:46<00:12,  1.74it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  93%|▉| 290/311 [02:46<00:12,  1.74it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  94%|▉| 291/311 [02:46<00:11,  1.75it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  94%|▉| 292/311 [02:46<00:10,  1.75it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  94%|▉| 293/311 [02:46<00:10,  1.76it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  95%|▉| 294/311 [02:47<00:09,  1.76it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  95%|▉| 295/311 [02:47<00:09,  1.76it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  95%|▉| 296/311 [02:47<00:08,  1.77it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  95%|▉| 297/311 [02:47<00:07,  1.77it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  96%|▉| 298/311 [02:47<00:07,  1.78it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  96%|▉| 299/311 [02:47<00:06,  1.78it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  96%|▉| 300/311 [02:48<00:06,  1.78it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  97%|▉| 301/311 [02:48<00:05,  1.79it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  97%|▉| 302/311 [02:48<00:05,  1.79it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  97%|▉| 303/311 [02:48<00:04,  1.80it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  98%|▉| 304/311 [02:48<00:03,  1.80it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  98%|▉| 305/311 [02:49<00:03,  1.80it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  98%|▉| 306/311 [02:49<00:02,  1.81it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  99%|▉| 307/311 [02:49<00:02,  1.81it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  99%|▉| 308/311 [02:49<00:01,  1.82it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24:  99%|▉| 309/311 [02:49<00:01,  1.82it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24: 100%|▉| 310/311 [02:49<00:00,  1.82it/s, loss=0.26, v_num=2-27, lr=3.7\u001b[A\n",
      "Epoch 24: 100%|█| 311/311 [02:50<00:00,  1.83it/s, loss=0.26, v_num=2-27, lr=3.7[NeMo I 2022-11-14 13:56:21 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             90.80      84.04      87.29        376\n",
      "    label_id: 1                                             87.59      83.14      85.31        433\n",
      "    label_id: 2                                             88.25      81.05      84.50        380\n",
      "    label_id: 3                                             77.40      94.54      85.12        366\n",
      "    label_id: 4                                             78.44      78.44      78.44        422\n",
      "    -------------------\n",
      "    micro avg                                               84.02      84.02      84.02       1977\n",
      "    macro avg                                               84.50      84.24      84.13       1977\n",
      "    weighted avg                                            84.49      84.02      84.03       1977\n",
      "    \n",
      "Epoch 24: 100%|█| 311/311 [02:50<00:00,  1.83it/s, loss=0.26, v_num=2-27, lr=3.7\n",
      "Epoch 24: 100%|█| 311/311 [02:50<00:00,  1.83it/s, loss=0.26, v_num=2-27, lr=3.7Epoch 24, global step 7000: 'val_loss' was not in top 3\n",
      "Epoch 25:   0%| | 0/311 [00:00<?, ?it/s, loss=0.26, v_num=2-27, lr=3.71e-6, val_[NeMo W 2022-11-14 13:56:25 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:56:25 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:56:25 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  90%|▉| 280/311 [02:41<00:17,  1.74it/s, loss=0.222, v_num=2-27, lr=2.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 13:59:06 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:59:06 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:59:06 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  90%|▉| 281/311 [02:41<00:17,  1.74it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  91%|▉| 282/311 [02:41<00:16,  1.74it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  91%|▉| 283/311 [02:42<00:16,  1.75it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  91%|▉| 284/311 [02:42<00:15,  1.75it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  92%|▉| 285/311 [02:42<00:14,  1.76it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  92%|▉| 286/311 [02:42<00:14,  1.76it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  92%|▉| 287/311 [02:42<00:13,  1.76it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  93%|▉| 288/311 [02:42<00:13,  1.77it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  93%|▉| 289/311 [02:43<00:12,  1.77it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  93%|▉| 290/311 [02:43<00:11,  1.78it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  94%|▉| 291/311 [02:43<00:11,  1.78it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  94%|▉| 292/311 [02:43<00:10,  1.78it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  94%|▉| 293/311 [02:43<00:10,  1.79it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  95%|▉| 294/311 [02:44<00:09,  1.79it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  95%|▉| 295/311 [02:44<00:08,  1.80it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  95%|▉| 296/311 [02:44<00:08,  1.80it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  95%|▉| 297/311 [02:44<00:07,  1.80it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  96%|▉| 298/311 [02:44<00:07,  1.81it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  96%|▉| 299/311 [02:44<00:06,  1.81it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  96%|▉| 300/311 [02:45<00:06,  1.82it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  97%|▉| 301/311 [02:45<00:05,  1.82it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  97%|▉| 302/311 [02:45<00:04,  1.82it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  97%|▉| 303/311 [02:45<00:04,  1.83it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  98%|▉| 304/311 [02:45<00:03,  1.83it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  98%|▉| 305/311 [02:46<00:03,  1.84it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  98%|▉| 306/311 [02:46<00:02,  1.84it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  99%|▉| 307/311 [02:46<00:02,  1.85it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  99%|▉| 308/311 [02:46<00:01,  1.85it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25:  99%|▉| 309/311 [02:46<00:01,  1.85it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25: 100%|▉| 310/311 [02:46<00:00,  1.86it/s, loss=0.222, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 25: 100%|█| 311/311 [02:47<00:00,  1.86it/s, loss=0.222, v_num=2-27, lr=2.[NeMo I 2022-11-14 13:59:12 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             89.47      85.90      87.65        376\n",
      "    label_id: 1                                             84.09      85.45      84.77        433\n",
      "    label_id: 2                                             90.00      75.79      82.29        380\n",
      "    label_id: 3                                             80.38      92.90      86.19        366\n",
      "    label_id: 4                                             79.45      81.52      80.47        422\n",
      "    -------------------\n",
      "    micro avg                                               84.22      84.22      84.22       1977\n",
      "    macro avg                                               84.68      84.31      84.27       1977\n",
      "    weighted avg                                            84.57      84.22      84.18       1977\n",
      "    \n",
      "Epoch 25: 100%|█| 311/311 [02:47<00:00,  1.86it/s, loss=0.222, v_num=2-27, lr=2.\n",
      "Epoch 25: 100%|█| 311/311 [02:47<00:00,  1.86it/s, loss=0.222, v_num=2-27, lr=2.Epoch 25, global step 7280: 'val_loss' was not in top 3\n",
      "Epoch 26:   0%| | 0/311 [00:00<?, ?it/s, loss=0.222, v_num=2-27, lr=2.97e-6, val[NeMo W 2022-11-14 13:59:17 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:59:17 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 13:59:17 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 26:  90%|▉| 280/311 [02:42<00:17,  1.72it/s, loss=0.24, v_num=2-27, lr=2.2\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 14:01:59 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:01:59 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-11-14 14:01:59 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  90%|▉| 281/311 [02:42<00:17,  1.73it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  91%|▉| 282/311 [02:43<00:16,  1.73it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  91%|▉| 284/311 [02:43<00:15,  1.74it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  92%|▉| 285/311 [02:43<00:14,  1.74it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  92%|▉| 286/311 [02:43<00:14,  1.75it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  92%|▉| 287/311 [02:43<00:13,  1.75it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  93%|▉| 288/311 [02:44<00:13,  1.76it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  94%|▉| 291/311 [02:44<00:11,  1.77it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  94%|▉| 292/311 [02:44<00:10,  1.77it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  94%|▉| 293/311 [02:45<00:10,  1.78it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  95%|▉| 296/311 [02:45<00:08,  1.79it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  95%|▉| 297/311 [02:45<00:07,  1.79it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  96%|▉| 298/311 [02:45<00:07,  1.80it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  96%|▉| 299/311 [02:46<00:06,  1.80it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  97%|▉| 301/311 [02:46<00:05,  1.81it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  97%|▉| 302/311 [02:46<00:04,  1.81it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  97%|▉| 303/311 [02:46<00:04,  1.82it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  98%|▉| 304/311 [02:47<00:03,  1.82it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  98%|▉| 306/311 [02:47<00:02,  1.83it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  99%|▉| 308/311 [02:47<00:01,  1.84it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26:  99%|▉| 309/311 [02:47<00:01,  1.84it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.24, v_num=2-27, lr=2.2\u001b[A\n",
      "Epoch 26: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.24, v_num=2-27, lr=2.2[NeMo I 2022-11-14 14:02:05 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             90.17      85.37      87.70        376\n",
      "    label_id: 1                                             86.38      84.99      85.68        433\n",
      "    label_id: 2                                             86.70      85.79      86.24        380\n",
      "    label_id: 3                                             86.63      92.08      89.27        366\n",
      "    label_id: 4                                             81.16      82.70      81.92        422\n",
      "    -------------------\n",
      "    micro avg                                               86.04      86.04      86.04       1977\n",
      "    macro avg                                               86.21      86.19      86.17       1977\n",
      "    weighted avg                                            86.10      86.04      86.04       1977\n",
      "    \n",
      "Epoch 26: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.24, v_num=2-27, lr=2.2\n",
      "Epoch 26: 100%|█| 311/311 [02:48<00:00,  1.85it/s, loss=0.24, v_num=2-27, lr=2.2Epoch 26, global step 7560: 'val_loss' was not in top 3\n",
      "Epoch 27:   0%| | 0/311 [00:00<?, ?it/s, loss=0.24, v_num=2-27, lr=2.22e-6, val_[NeMo W 2022-11-14 14:02:09 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:02:09 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:02:09 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 27:  90%|▉| 280/311 [02:43<00:18,  1.71it/s, loss=0.193, v_num=2-27, lr=1.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 14:04:52 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:04:52 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:04:52 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  91%|▉| 282/311 [02:43<00:16,  1.72it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  91%|▉| 283/311 [02:44<00:16,  1.72it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  91%|▉| 284/311 [02:44<00:15,  1.73it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  92%|▉| 285/311 [02:44<00:14,  1.73it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  92%|▉| 287/311 [02:44<00:13,  1.74it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  93%|▉| 289/311 [02:45<00:12,  1.75it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  93%|▉| 290/311 [02:45<00:11,  1.75it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  94%|▉| 291/311 [02:45<00:11,  1.76it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  94%|▉| 292/311 [02:45<00:10,  1.76it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  95%|▉| 294/311 [02:46<00:09,  1.77it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  95%|▉| 295/311 [02:46<00:09,  1.77it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  95%|▉| 296/311 [02:46<00:08,  1.78it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  95%|▉| 297/311 [02:46<00:07,  1.78it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  96%|▉| 299/311 [02:46<00:06,  1.79it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  96%|▉| 300/311 [02:47<00:06,  1.79it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  97%|▉| 301/311 [02:47<00:05,  1.80it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  97%|▉| 302/311 [02:47<00:04,  1.80it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  98%|▉| 304/311 [02:47<00:03,  1.81it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  98%|▉| 305/311 [02:48<00:03,  1.81it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  98%|▉| 306/311 [02:48<00:02,  1.82it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  99%|▉| 307/311 [02:48<00:02,  1.82it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27:  99%|▉| 309/311 [02:48<00:01,  1.83it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27: 100%|▉| 310/311 [02:49<00:00,  1.83it/s, loss=0.193, v_num=2-27, lr=1.\u001b[A\n",
      "Epoch 27: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.193, v_num=2-27, lr=1.[NeMo I 2022-11-14 14:04:58 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             88.86      86.97      87.90        376\n",
      "    label_id: 1                                             89.47      82.45      85.82        433\n",
      "    label_id: 2                                             86.36      85.00      85.68        380\n",
      "    label_id: 3                                             74.14      93.99      82.89        366\n",
      "    label_id: 4                                             83.06      73.22      77.83        422\n",
      "    -------------------\n",
      "    micro avg                                               83.97      83.97      83.97       1977\n",
      "    macro avg                                               84.38      84.33      84.02       1977\n",
      "    weighted avg                                            84.55      83.97      83.94       1977\n",
      "    \n",
      "Epoch 27: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.193, v_num=2-27, lr=1.\n",
      "Epoch 27: 100%|█| 311/311 [02:49<00:00,  1.84it/s, loss=0.193, v_num=2-27, lr=1.Epoch 27, global step 7840: 'val_loss' was not in top 3\n",
      "Epoch 28:   0%| | 0/311 [00:00<?, ?it/s, loss=0.193, v_num=2-27, lr=1.48e-6, val[NeMo W 2022-11-14 14:05:02 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:05:02 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:05:02 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 28:  90%|▉| 280/311 [02:42<00:18,  1.72it/s, loss=0.237, v_num=2-27, lr=7.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 14:07:45 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:07:45 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:07:45 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  91%|▉| 282/311 [02:43<00:16,  1.73it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  91%|▉| 284/311 [02:43<00:15,  1.73it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  92%|▉| 285/311 [02:43<00:14,  1.74it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  92%|▉| 287/311 [02:44<00:13,  1.75it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  94%|▉| 291/311 [02:44<00:11,  1.76it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  94%|▉| 292/311 [02:45<00:10,  1.77it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  95%|▉| 296/311 [02:45<00:08,  1.78it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  95%|▉| 297/311 [02:46<00:07,  1.79it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  96%|▉| 299/311 [02:46<00:06,  1.80it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  97%|▉| 301/311 [02:46<00:05,  1.80it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  97%|▉| 302/311 [02:47<00:04,  1.81it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  98%|▉| 304/311 [02:47<00:03,  1.82it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  98%|▉| 306/311 [02:47<00:02,  1.82it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28:  99%|▉| 309/311 [02:48<00:01,  1.84it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.237, v_num=2-27, lr=7.\u001b[A\n",
      "Epoch 28: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.237, v_num=2-27, lr=7.[NeMo I 2022-11-14 14:07:51 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             88.67      85.37      86.99        376\n",
      "    label_id: 1                                             87.90      82.22      84.96        433\n",
      "    label_id: 2                                             82.48      89.21      85.71        380\n",
      "    label_id: 3                                             86.15      91.80      88.89        366\n",
      "    label_id: 4                                             82.89      80.33      81.59        422\n",
      "    -------------------\n",
      "    micro avg                                               85.53      85.53      85.53       1977\n",
      "    macro avg                                               85.62      85.79      85.63       1977\n",
      "    weighted avg                                            85.61      85.53      85.50       1977\n",
      "    \n",
      "Epoch 28: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.237, v_num=2-27, lr=7.\n",
      "Epoch 28: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.237, v_num=2-27, lr=7.\u001b[AEpoch 28, global step 8120: 'val_loss' was not in top 3\n",
      "Epoch 29:   0%| | 0/311 [00:00<?, ?it/s, loss=0.237, v_num=2-27, lr=7.43e-7, val[NeMo W 2022-11-14 14:07:55 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:07:55 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:07:55 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Epoch 29:  90%|▉| 280/311 [02:42<00:18,  1.72it/s, loss=0.197, v_num=2-27, lr=2.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A[NeMo W 2022-11-14 14:10:38 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:10:38 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:10:38 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "\n",
      "Validation:   0%|                                        | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  90%|▉| 281/311 [02:43<00:17,  1.72it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  91%|▉| 282/311 [02:43<00:16,  1.73it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  91%|▉| 283/311 [02:43<00:16,  1.73it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  91%|▉| 284/311 [02:43<00:15,  1.73it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  92%|▉| 285/311 [02:43<00:14,  1.74it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  92%|▉| 286/311 [02:44<00:14,  1.74it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  92%|▉| 287/311 [02:44<00:13,  1.75it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  93%|▉| 288/311 [02:44<00:13,  1.75it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  93%|▉| 289/311 [02:44<00:12,  1.76it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  93%|▉| 290/311 [02:44<00:11,  1.76it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  94%|▉| 291/311 [02:44<00:11,  1.76it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  94%|▉| 292/311 [02:45<00:10,  1.77it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  94%|▉| 293/311 [02:45<00:10,  1.77it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  95%|▉| 294/311 [02:45<00:09,  1.78it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  95%|▉| 295/311 [02:45<00:08,  1.78it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  95%|▉| 296/311 [02:45<00:08,  1.78it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  95%|▉| 297/311 [02:46<00:07,  1.79it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  96%|▉| 298/311 [02:46<00:07,  1.79it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  96%|▉| 299/311 [02:46<00:06,  1.80it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  96%|▉| 300/311 [02:46<00:06,  1.80it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  97%|▉| 301/311 [02:46<00:05,  1.80it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  97%|▉| 302/311 [02:47<00:04,  1.81it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  97%|▉| 303/311 [02:47<00:04,  1.81it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  98%|▉| 304/311 [02:47<00:03,  1.82it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  98%|▉| 305/311 [02:47<00:03,  1.82it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  98%|▉| 306/311 [02:47<00:02,  1.82it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  99%|▉| 307/311 [02:47<00:02,  1.83it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  99%|▉| 308/311 [02:48<00:01,  1.83it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29:  99%|▉| 309/311 [02:48<00:01,  1.84it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29: 100%|▉| 310/311 [02:48<00:00,  1.84it/s, loss=0.197, v_num=2-27, lr=2.\u001b[A\n",
      "Epoch 29: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.197, v_num=2-27, lr=2.[NeMo I 2022-11-14 14:10:44 text_classification_model:142] val_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             89.61      84.84      87.16        376\n",
      "    label_id: 1                                             87.23      83.60      85.38        433\n",
      "    label_id: 2                                             86.56      84.74      85.64        380\n",
      "    label_id: 3                                             84.71      92.35      88.37        366\n",
      "    label_id: 4                                             80.46      82.94      81.68        422\n",
      "    -------------------\n",
      "    micro avg                                               85.53      85.53      85.53       1977\n",
      "    macro avg                                               85.71      85.69      85.64       1977\n",
      "    weighted avg                                            85.64      85.53      85.53       1977\n",
      "    \n",
      "Epoch 29: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.197, v_num=2-27, lr=2.\n",
      "Epoch 29: 100%|█| 311/311 [02:48<00:00,  1.84it/s, loss=0.197, v_num=2-27, lr=2.Epoch 29, global step 8400: 'val_loss' was not in top 3\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "Epoch 29: 100%|█| 311/311 [02:52<00:00,  1.80it/s, loss=0.197, v_num=2-27, lr=2.\n",
      "[NeMo I 2022-11-14 14:10:55 text_classification_with_bert:107] Training finished!\n",
      "[NeMo I 2022-11-14 14:10:55 text_classification_with_bert:108] ===========================================================================================\n",
      "[NeMo I 2022-11-14 14:10:57 text_classification_with_bert:113] Model is saved into `.nemo` file: text_classification_model.nemo\n",
      "[NeMo I 2022-11-14 14:10:57 text_classification_with_bert:117] ===========================================================================================\n",
      "[NeMo I 2022-11-14 14:10:57 text_classification_with_bert:118] Starting the testing of the trained model on test set...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "Testing: 0it [00:00, ?it/s][NeMo W 2022-11-14 14:10:58 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:10:58 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo W 2022-11-14 14:10:58 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "Testing DataLoader 0: 100%|█████████████████████| 31/31 [00:05<00:00,  5.67it/s][NeMo I 2022-11-14 14:11:04 text_classification_model:142] test_report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    label_id: 0                                             85.95      85.95      85.95        363\n",
      "    label_id: 1                                             89.38      82.84      85.99        437\n",
      "    label_id: 2                                             83.93      80.59      82.23        376\n",
      "    label_id: 3                                             85.55      91.98      88.65        399\n",
      "    label_id: 4                                             78.10      81.39      79.71        403\n",
      "    -------------------\n",
      "    micro avg                                               84.53      84.53      84.53       1978\n",
      "    macro avg                                               84.58      84.55      84.50       1978\n",
      "    weighted avg                                            84.64      84.53      84.52       1978\n",
      "    \n",
      "Testing DataLoader 0: 100%|█████████████████████| 31/31 [00:05<00:00,  5.66it/s]\n",
      "[NeMo I 2022-11-14 14:11:05 text_classification_with_bert:120] Testing finished!\n",
      "[NeMo I 2022-11-14 14:11:05 text_classification_with_bert:121] ===========================================================================================\n",
      "[NeMo I 2022-11-14 14:11:05 text_classification_with_bert:125] ===========================================================================================\n",
      "[NeMo I 2022-11-14 14:11:05 text_classification_with_bert:126] Starting the inference on some sample queries...\n",
      "[NeMo W 2022-11-14 14:11:06 nemo_logging:349] /home/mjk0307/nemo-text-classification/myenv3/lib/python3.8/site-packages/nemo/collections/nlp/data/text_classification/text_classification_dataset.py:203: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "      torch.LongTensor(padded_input_ids),\n",
      "    \n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:130] The prediction results of some sample queries with the trained model:\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:132] Query : by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:133] Predicted label: 1\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:132] Query : director rob marshall went out gunning to make a great one .\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:133] Predicted label: 1\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:132] Query : uneasy mishmash of styles and genres .\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:133] Predicted label: 1\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:135] Inference finished!\n",
      "[NeMo I 2022-11-14 14:11:06 text_classification_with_bert:136] ===========================================================================================\n",
      "CPU times: user 58.1 s, sys: 10 s, total: 1min 8s\n",
      "Wall time: 1h 28min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The training takes about 2 minutes to run\n",
    "\n",
    "TC_DIR = \"/home/mjk0307/nemo-text-classification/nemo/examples/nlp/text_classification\"\n",
    "\n",
    "# set the values we want to override\n",
    "NUM_CLASSES = 5\n",
    "MAX_SEQ_LENGTH = 256\n",
    "PATH_TO_TRAIN_FILE = \"/home/mjk0307/nemo-text-classification/data/auc/train.tsv\"\n",
    "PATH_TO_VAL_FILE = \"/home/mjk0307/nemo-text-classification/data/auc/dev.tsv\"\n",
    "PATH_TO_TEST_FILE = \"/home/mjk0307/nemo-text-classification/data/auc/test.tsv\"\n",
    "CLASS_LABEL_FILE=\"/home/mjk0307/nemo-text-classification/data/auc/class_labels.txt\"\n",
    "# disease domain inference sample answers should be 0, 1, 2 \n",
    "# INFER_SAMPLES_0 = \"In contrast no mutations were detected in the p53 gene suggesting that this tumour suppressor is not frequently altered in this leukaemia \"\n",
    "# INFER_SAMPLES_1 = \"The first predictive testing for Huntington disease  was based on analysis of linked polymorphic DNA markers to estimate the likelihood of inheriting the mutation for HD\"\n",
    "# INFER_SAMPLES_2 = \"Further studies suggested that low dilutions of C5D serum contain a factor or factors interfering at some step in the hemolytic assay of C5 rather than a true C5 inhibitor or inactivator\"\n",
    "MAX_EPOCHS = 30\n",
    "\n",
    "# Run the training script, overriding the config values in the command line\n",
    "!python $TC_DIR/text_classification_with_bert.py \\\n",
    "        model.dataset.num_classes=$NUM_CLASSES \\\n",
    "        model.dataset.max_seq_length=$MAX_SEQ_LENGTH \\\n",
    "        model.train_ds.file_path=$PATH_TO_TRAIN_FILE \\\n",
    "        model.validation_ds.file_path=$PATH_TO_VAL_FILE \\\n",
    "        model.test_ds.file_path=$PATH_TO_TEST_FILE \\\n",
    "        model.class_labels.class_labels_file=$CLASS_LABEL_FILE \\\n",
    "        trainer.max_epochs=$MAX_EPOCHS \\\n",
    "        trainer.accelerator='gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057b213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
